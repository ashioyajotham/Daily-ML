{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9300bef6",
   "metadata": {},
   "source": [
    "# Kenya Clinical Reasoning Challenge\n",
    "\n",
    "This notebook explores and builds a model for the Kenya Clinical Reasoning Challenge, which focuses on predicting clinician responses to medical scenarios in rural Kenyan healthcare settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a8bbcb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61be68b",
   "metadata": {},
   "source": [
    "## Data Loading\n",
    "\n",
    "Let's load the training and testing datasets to begin our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee6f5b71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset shape: (400, 12)\n",
      "Test dataset shape: (100, 7)\n"
     ]
    }
   ],
   "source": [
    "# Load the train and test datasets\n",
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')\n",
    "\n",
    "# Also load the raw versions which may contain additional information\n",
    "train_raw_df = pd.read_csv('train_raw.csv')\n",
    "test_raw_df = pd.read_csv('test_raw.csv')\n",
    "\n",
    "print(f\"Train dataset shape: {train_df.shape}\")\n",
    "print(f\"Test dataset shape: {test_df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0656aca",
   "metadata": {},
   "source": [
    "## Data Exploration\n",
    "\n",
    "Let's examine the structure of our datasets and understand the clinical scenarios better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46f8977b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Master_Index</th>\n",
       "      <th>County</th>\n",
       "      <th>Health level</th>\n",
       "      <th>Years of Experience</th>\n",
       "      <th>Prompt</th>\n",
       "      <th>Nursing Competency</th>\n",
       "      <th>Clinical Panel</th>\n",
       "      <th>Clinician</th>\n",
       "      <th>GPT4.0</th>\n",
       "      <th>LLAMA</th>\n",
       "      <th>GEMINI</th>\n",
       "      <th>DDX SNOMED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID_VBWWP</td>\n",
       "      <td>uasin gishu</td>\n",
       "      <td>sub county hospitals and nursing homes</td>\n",
       "      <td>18.0</td>\n",
       "      <td>i am a nurse with 18 years of experience in ge...</td>\n",
       "      <td>pediatric emergency burns</td>\n",
       "      <td>surgery</td>\n",
       "      <td>summary a 4 year old with 5 superficial burns ...</td>\n",
       "      <td>given your vast experience as a nurse in uasin...</td>\n",
       "      <td>1 immediate treatment protocol for second degr...</td>\n",
       "      <td>here s a response addressing the questions reg...</td>\n",
       "      <td>288514009 burn involving 5 percent of body sur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID_XMBBY</td>\n",
       "      <td>uasin gishu</td>\n",
       "      <td>national referral hospitals</td>\n",
       "      <td>17.0</td>\n",
       "      <td>i am a nurse with 17 years of experience in ge...</td>\n",
       "      <td>child health</td>\n",
       "      <td>paediatrics</td>\n",
       "      <td>summary 6 year old present with vomiting and a...</td>\n",
       "      <td>clinical summary • a 6 year old girl with know...</td>\n",
       "      <td>based on the symptoms and signs you ve describ...</td>\n",
       "      <td>based on the presentation the 6 year old girl ...</td>\n",
       "      <td>420270002 ketoacidosis due to type 1 diabetes ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID_JZNZW</td>\n",
       "      <td>kiambu</td>\n",
       "      <td>sub county hospitals and nursing homes</td>\n",
       "      <td>12.0</td>\n",
       "      <td>i am a nurse with 12 years of experience in ge...</td>\n",
       "      <td>general emergency</td>\n",
       "      <td>internal medicine</td>\n",
       "      <td>summary a 47 year old man presents with severe...</td>\n",
       "      <td>in this case you re dealing with a 47 year old...</td>\n",
       "      <td>firstly i must commend you on your thorough hi...</td>\n",
       "      <td>this 47 year old male presenting with severe r...</td>\n",
       "      <td>13200003 peptic ulcer disorder 25458004 acute ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID_QOQTK</td>\n",
       "      <td>uasin gishu</td>\n",
       "      <td>national referral hospitals</td>\n",
       "      <td>12.0</td>\n",
       "      <td>i am a nurse with 12 years of experience in pr...</td>\n",
       "      <td>critical care</td>\n",
       "      <td>internal medicine</td>\n",
       "      <td>summary 72 year old female with inability to w...</td>\n",
       "      <td>given er s clinical presentation and vitals th...</td>\n",
       "      <td>to me with this query based on the information...</td>\n",
       "      <td>this 92 year old female patient er presents wi...</td>\n",
       "      <td>14760008 constipation finding 419284004 altere...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID_ZFJBM</td>\n",
       "      <td>uasin gishu</td>\n",
       "      <td>national referral hospitals</td>\n",
       "      <td>16.0</td>\n",
       "      <td>i am a nurse with 16 years of experience in ge...</td>\n",
       "      <td>adult health</td>\n",
       "      <td>internal medicine</td>\n",
       "      <td>a 22 year old female presents with headache di...</td>\n",
       "      <td>the 22 year old female patient is presenting w...</td>\n",
       "      <td>thank you for presenting this case based on th...</td>\n",
       "      <td>this 22 year old female patient presents with ...</td>\n",
       "      <td>95874006 carbon monoxide poisoning from fire d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Master_Index       County                            Health level  \\\n",
       "0     ID_VBWWP  uasin gishu  sub county hospitals and nursing homes   \n",
       "1     ID_XMBBY  uasin gishu             national referral hospitals   \n",
       "2     ID_JZNZW       kiambu  sub county hospitals and nursing homes   \n",
       "3     ID_QOQTK  uasin gishu             national referral hospitals   \n",
       "4     ID_ZFJBM  uasin gishu             national referral hospitals   \n",
       "\n",
       "   Years of Experience                                             Prompt  \\\n",
       "0                 18.0  i am a nurse with 18 years of experience in ge...   \n",
       "1                 17.0  i am a nurse with 17 years of experience in ge...   \n",
       "2                 12.0  i am a nurse with 12 years of experience in ge...   \n",
       "3                 12.0  i am a nurse with 12 years of experience in pr...   \n",
       "4                 16.0  i am a nurse with 16 years of experience in ge...   \n",
       "\n",
       "          Nursing Competency     Clinical Panel  \\\n",
       "0  pediatric emergency burns            surgery   \n",
       "1               child health        paediatrics   \n",
       "2          general emergency  internal medicine   \n",
       "3              critical care  internal medicine   \n",
       "4               adult health  internal medicine   \n",
       "\n",
       "                                           Clinician  \\\n",
       "0  summary a 4 year old with 5 superficial burns ...   \n",
       "1  summary 6 year old present with vomiting and a...   \n",
       "2  summary a 47 year old man presents with severe...   \n",
       "3  summary 72 year old female with inability to w...   \n",
       "4  a 22 year old female presents with headache di...   \n",
       "\n",
       "                                              GPT4.0  \\\n",
       "0  given your vast experience as a nurse in uasin...   \n",
       "1  clinical summary • a 6 year old girl with know...   \n",
       "2  in this case you re dealing with a 47 year old...   \n",
       "3  given er s clinical presentation and vitals th...   \n",
       "4  the 22 year old female patient is presenting w...   \n",
       "\n",
       "                                               LLAMA  \\\n",
       "0  1 immediate treatment protocol for second degr...   \n",
       "1  based on the symptoms and signs you ve describ...   \n",
       "2  firstly i must commend you on your thorough hi...   \n",
       "3  to me with this query based on the information...   \n",
       "4  thank you for presenting this case based on th...   \n",
       "\n",
       "                                              GEMINI  \\\n",
       "0  here s a response addressing the questions reg...   \n",
       "1  based on the presentation the 6 year old girl ...   \n",
       "2  this 47 year old male presenting with severe r...   \n",
       "3  this 92 year old female patient er presents wi...   \n",
       "4  this 22 year old female patient presents with ...   \n",
       "\n",
       "                                          DDX SNOMED  \n",
       "0  288514009 burn involving 5 percent of body sur...  \n",
       "1  420270002 ketoacidosis due to type 1 diabetes ...  \n",
       "2  13200003 peptic ulcer disorder 25458004 acute ...  \n",
       "3  14760008 constipation finding 419284004 altere...  \n",
       "4  95874006 carbon monoxide poisoning from fire d...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first few rows of the training data\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8072a4e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset columns:\n",
      "['Master_Index', 'County', 'Health level', 'Years of Experience', 'Prompt', 'Nursing Competency', 'Clinical Panel', 'Clinician', 'GPT4.0', 'LLAMA', 'GEMINI', 'DDX SNOMED']\n",
      "\n",
      "Test dataset columns:\n",
      "['Master_Index', 'County', 'Health level', 'Years of Experience', 'Prompt', 'Nursing Competency', 'Clinical Panel']\n"
     ]
    }
   ],
   "source": [
    "# Check for columns in the training set\n",
    "print(\"Train dataset columns:\")\n",
    "print(train_df.columns.tolist())\n",
    "\n",
    "print(\"\\nTest dataset columns:\")\n",
    "print(test_df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06dd83e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in train dataset:\n",
      "Master_Index             0\n",
      "County                   0\n",
      "Health level             0\n",
      "Years of Experience    100\n",
      "Prompt                   0\n",
      "Nursing Competency       0\n",
      "Clinical Panel           0\n",
      "Clinician                0\n",
      "GPT4.0                   0\n",
      "LLAMA                    0\n",
      "GEMINI                   0\n",
      "DDX SNOMED               1\n",
      "dtype: int64\n",
      "\n",
      "Missing values in test dataset:\n",
      "Master_Index            0\n",
      "County                  0\n",
      "Health level            0\n",
      "Years of Experience    25\n",
      "Prompt                  0\n",
      "Nursing Competency      0\n",
      "Clinical Panel          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(\"Missing values in train dataset:\")\n",
    "print(train_df.isnull().sum())\n",
    "\n",
    "print(\"\\nMissing values in test dataset:\")\n",
    "print(test_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65758bd3",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "Based on the challenge description, we need to transform the clinician responses according to specific rules:\n",
    "1. Deal with missing values\n",
    "2. Convert all text to lowercase\n",
    "3. Remove punctuation\n",
    "4. Replace paragraphs with spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "009be291",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample clinician column before cleaning:\n",
      "summary a 4 year old with 5 superficial burns no other injuries immediate management paracetamol analgesics to to ensure child has minimal or no pain cleaning and frosting of wound with silver sulpha fizika topical prophylactic can be considered in this case good nutrition high protein diet\n",
      "\n",
      "---\n",
      "\n",
      "Sample clinician column after cleaning:\n",
      "immediate management paracetamol analgesics to to ensure child has minimal or no pain cleaning and frosting of wound with silver sulpha fizika topical prophylactic can be considered in this case good nutrition high protein diet\n",
      "\n",
      "---\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of clinician responses that started with 'summary': 316 out of 400\n"
     ]
    }
   ],
   "source": [
    "# Dealing with missing values\n",
    "# Years of experience column has some missing values, let's fill them with the mean\n",
    "train_df['Years of Experience'].fillna(train_df['Years of Experience'].mean(), inplace=True)    \n",
    "test_df['Years of Experience'].fillna(test_df['Years of Experience'].mean(), inplace=True)\n",
    "\n",
    "# DDX SNOMED column has some missing values, let's fill them with the mode\n",
    "train_df['DDX SNOMED'].fillna(train_df['DDX SNOMED'].mode()[0], inplace=True)\n",
    "\n",
    "# Clean up the 'Clinician' column by removing the \"summary\" prefix\n",
    "def clean_summary_prefix(text):\n",
    "    \"\"\"Remove 'summary' and redundant text from the beginning of clinician responses\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return text\n",
    "    \n",
    "    # Check if the text starts with 'summary'\n",
    "    text = text.lower().strip()\n",
    "    if text.startswith('summary'):\n",
    "        # Find where the actual content begins after the case summary\n",
    "        # Typically after details about the patient, symptoms, vitals, etc.\n",
    "        \n",
    "        # Look for common transition points where the actual medical advice begins\n",
    "        content_markers = [\n",
    "            'diagnosis:', 'diagnosis', 'management:', 'management',\n",
    "            'treatment:', 'treatment', 'plan:', 'plan',\n",
    "            'investigations:', 'investigations', 'ddx', 'differentials:',\n",
    "            'immediate management', 'how to manage'\n",
    "        ]\n",
    "        \n",
    "        # First, try to find the position of any content markers\n",
    "        positions = [text.find(marker) for marker in content_markers if text.find(marker) > 0]\n",
    "        \n",
    "        if positions:\n",
    "            # Find the earliest marker position\n",
    "            start_pos = min(positions)\n",
    "            return text[start_pos:].strip()\n",
    "        else:\n",
    "            # If no marker is found, check for end of patient description\n",
    "            # This typically contains age, vitals, symptoms in the summary\n",
    "            # Often ends with phrases like 'vitals are normal', 'temp', 'bp', etc.\n",
    "            vital_markers = ['vitals', 'bp', 'temp', 'pulse', 'spo2', 'vital signs']\n",
    "            vital_positions = []\n",
    "            \n",
    "            # Find the last mention of vitals\n",
    "            for marker in vital_markers:\n",
    "                pos = text.rfind(marker, 0, len(text)//2)  # Search in the first half\n",
    "                if pos > 0:\n",
    "                    vital_positions.append(pos)\n",
    "            \n",
    "            if vital_positions:\n",
    "                # Find where the vital signs description likely ends\n",
    "                vital_pos = max(vital_positions)\n",
    "                end_of_vitals = text.find('.', vital_pos)\n",
    "                if end_of_vitals > 0:\n",
    "                    return text[end_of_vitals + 1:].strip()\n",
    "            \n",
    "            # Last resort: look for a question that might start the clinical response\n",
    "            questions = ['what ', 'how ', 'why ', 'when ', 'which ', 'is ', 'are ', 'can ', 'should ']\n",
    "            for q in questions:\n",
    "                q_pos = text.find(q, len('summary') + 5)  # Search after 'summary' + some buffer\n",
    "                if q_pos > 0:\n",
    "                    # Find the beginning of the sentence containing the question\n",
    "                    sentence_start = text.rfind('. ', 0, q_pos)\n",
    "                    if sentence_start > 0:\n",
    "                        return text[sentence_start + 2:].strip()\n",
    "                    else:\n",
    "                        return text[q_pos:].strip()\n",
    "            \n",
    "            # If all else fails, just remove 'summary' and a bit after it\n",
    "            return text[len('summary') + 2:].strip()\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Apply the cleaning function to the Clinician column\n",
    "print(\"Sample clinician column before cleaning:\")\n",
    "print(train_df['Clinician'].iloc[0])\n",
    "print(\"\\n---\\n\")\n",
    "\n",
    "train_df['Clinician'] = train_df['Clinician'].apply(clean_summary_prefix)\n",
    "\n",
    "print(\"Sample clinician column after cleaning:\")\n",
    "print(train_df['Clinician'].iloc[0])\n",
    "print(\"\\n---\\n\")\n",
    "\n",
    "# Check how many rows had the 'summary' prefix\n",
    "original_texts = pd.read_csv('train.csv')['Clinician']\n",
    "summary_count = sum(1 for text in original_texts if str(text).lower().strip().startswith('summary'))\n",
    "print(f\"Number of clinician responses that started with 'summary': {summary_count} out of {len(train_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f7626bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate rows in train dataset:\n",
      "0\n",
      "\n",
      "Duplicate rows in test dataset:\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicates\n",
    "print(\"Duplicate rows in train dataset:\")\n",
    "print(train_df.duplicated().sum())\n",
    "\n",
    "print(\"\\nDuplicate rows in test dataset:\")\n",
    "print(test_df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4154f799",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "Let's create features that will help our model understand the clinical scenarios better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "40f90481",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLTK resources downloaded successfully\n",
      "\n",
      "Training data with new features:\n",
      "   Patient_Age Patient_Gender  Is_Pediatric  Is_Emergency Experience_Level  \\\n",
      "0          4.0        Unknown          True          True           Expert   \n",
      "1          6.0         Female          True          True           Expert   \n",
      "2          NaN           Male         False         False           Senior   \n",
      "3          NaN         Female         False          True           Senior   \n",
      "4         22.0         Female         False         False           Expert   \n",
      "\n",
      "   Facility_Complexity  \n",
      "0                    2  \n",
      "1                    3  \n",
      "2                    2  \n",
      "3                    3  \n",
      "4                    3  \n",
      "\n",
      "Total features in training data: 166\n",
      "Total features in test data: 161\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "!pip install -q nltk\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Download necessary NLTK data\n",
    "try:\n",
    "    nltk.download('punkt', quiet=True)\n",
    "    nltk.download('stopwords', quiet=True)\n",
    "    print(\"NLTK resources downloaded successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"Error downloading NLTK resources: {e}\")\n",
    "\n",
    "# 1. Create nurse experience/seniority categories\n",
    "def categorize_experience(years):\n",
    "    \"\"\"Categorize years of experience into seniority levels.\"\"\"\n",
    "    if years < 5:\n",
    "        return 'Junior'\n",
    "    elif years < 10:\n",
    "        return 'Intermediate'\n",
    "    elif years < 15:\n",
    "        return 'Senior'\n",
    "    else:\n",
    "        return 'Expert'\n",
    "\n",
    "# Apply to both datasets\n",
    "train_df['Experience_Level'] = train_df['Years of Experience'].apply(categorize_experience)\n",
    "test_df['Experience_Level'] = test_df['Years of Experience'].apply(categorize_experience)\n",
    "\n",
    "# 2. Extract patient demographics from prompts\n",
    "def extract_patient_demographics(text):\n",
    "    \"\"\"Extract patient age, gender, and other key demographics from prompt text.\"\"\"\n",
    "    demographics = {}\n",
    "    \n",
    "    # Extract age\n",
    "    age_pattern = r'(\\d+)[ -](?:year|yr)[ -]old'\n",
    "    age_match = re.search(age_pattern, text.lower())\n",
    "    if age_match:\n",
    "        demographics['age'] = int(age_match.group(1))\n",
    "    else:\n",
    "        demographics['age'] = None\n",
    "    \n",
    "    # Extract gender\n",
    "    if re.search(r'\\b(male|man|boy|he|him)\\b', text.lower()):\n",
    "        demographics['gender'] = 'Male'\n",
    "    elif re.search(r'\\b(female|woman|girl|she|her)\\b', text.lower()):\n",
    "        demographics['gender'] = 'Female'\n",
    "    else:\n",
    "        demographics['gender'] = 'Unknown'\n",
    "    \n",
    "    # Pediatric vs Adult\n",
    "    demographics['is_pediatric'] = False\n",
    "    if 'age' in demographics and demographics['age'] is not None:\n",
    "        if demographics['age'] < 18:\n",
    "            demographics['is_pediatric'] = True\n",
    "    elif re.search(r'\\b(child|infant|baby|toddler|newborn)\\b', text.lower()):\n",
    "        demographics['is_pediatric'] = True\n",
    "    \n",
    "    # Extract if emergency\n",
    "    demographics['is_emergency'] = bool(re.search(r'\\b(emergency|urgent|critical|immediately|collapse)\\b', text.lower()))\n",
    "    \n",
    "    return demographics\n",
    "\n",
    "# Apply to both datasets\n",
    "train_demographics = train_df['Prompt'].apply(extract_patient_demographics)\n",
    "test_demographics = test_df['Prompt'].apply(extract_patient_demographics)\n",
    "\n",
    "# Convert the dictionaries to dataframe columns\n",
    "train_df['Patient_Age'] = train_demographics.apply(lambda x: x['age'])\n",
    "train_df['Patient_Gender'] = train_demographics.apply(lambda x: x['gender'])\n",
    "train_df['Is_Pediatric'] = train_demographics.apply(lambda x: x['is_pediatric'])\n",
    "train_df['Is_Emergency'] = train_demographics.apply(lambda x: x['is_emergency'])\n",
    "\n",
    "test_df['Patient_Age'] = test_demographics.apply(lambda x: x['age'])\n",
    "test_df['Patient_Gender'] = test_demographics.apply(lambda x: x['gender'])\n",
    "test_df['Is_Pediatric'] = test_demographics.apply(lambda x: x['is_pediatric'])\n",
    "test_df['Is_Emergency'] = test_demographics.apply(lambda x: x['is_emergency'])\n",
    "\n",
    "# 3. Extract symptoms and conditions (medical NLP features)\n",
    "def extract_medical_keywords(text):\n",
    "    \"\"\"Extract key medical terms from the prompt.\"\"\"\n",
    "    # Common symptoms and conditions to look for\n",
    "    keywords = [\n",
    "        'fever', 'pain', 'cough', 'headache', 'nausea', 'vomiting', 'diarrhea',\n",
    "        'bleeding', 'swelling', 'rash', 'fatigue', 'weakness', 'difficulty breathing',\n",
    "        'hypertension', 'diabetes', 'asthma', 'hiv', 'tuberculosis', 'malaria',\n",
    "        'pneumonia', 'wound', 'injury', 'fracture', 'burn', 'infection'\n",
    "    ]\n",
    "    \n",
    "    found_keywords = []\n",
    "    text_lower = text.lower()\n",
    "    \n",
    "    for keyword in keywords:\n",
    "        if keyword in text_lower:\n",
    "            found_keywords.append(keyword)\n",
    "    \n",
    "    return found_keywords\n",
    "\n",
    "# Apply to both datasets\n",
    "train_df['Medical_Keywords'] = train_df['Prompt'].apply(extract_medical_keywords)\n",
    "test_df['Medical_Keywords'] = test_df['Prompt'].apply(extract_medical_keywords)\n",
    "\n",
    "# Create binary features for important medical conditions\n",
    "for condition in ['fever', 'pain', 'cough', 'bleeding', 'hypertension', 'diabetes']:\n",
    "    train_df[f'Has_{condition.capitalize()}'] = train_df['Medical_Keywords'].apply(lambda x: condition in x)\n",
    "    test_df[f'Has_{condition.capitalize()}'] = test_df['Medical_Keywords'].apply(lambda x: condition in x)\n",
    "\n",
    "# 4. Hospital level complexity (higher level facilities can handle more complex cases)\n",
    "def hospital_complexity(facility_type):\n",
    "    \"\"\"Assign a complexity score based on health facility level.\"\"\"\n",
    "    facility_type = facility_type.lower()\n",
    "    if 'national referral' in facility_type:\n",
    "        return 3  # Highest complexity\n",
    "    elif 'sub-county' in facility_type or 'sub county' in facility_type:\n",
    "        return 2  # Medium complexity\n",
    "    elif 'health centres' in facility_type or 'health center' in facility_type:\n",
    "        return 1\n",
    "    else:  # Dispensaries, private clinics\n",
    "        return 0  # Basic care\n",
    "\n",
    "train_df['Facility_Complexity'] = train_df['Health level'].apply(hospital_complexity)\n",
    "test_df['Facility_Complexity'] = test_df['Health level'].apply(hospital_complexity)\n",
    "\n",
    "# Display the data with new features\n",
    "print(\"\\nTraining data with new features:\")\n",
    "print(train_df[['Patient_Age', 'Patient_Gender', 'Is_Pediatric', 'Is_Emergency', 'Experience_Level', 'Facility_Complexity']].head())\n",
    "\n",
    "# 5. One-hot encode categorical features\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "categorical_features = ['Experience_Level', 'Patient_Gender', 'Nursing Competency', 'Clinical Panel']\n",
    "for feature in categorical_features:\n",
    "    if feature in train_df.columns and feature in test_df.columns:\n",
    "        # Get all unique values from both train and test\n",
    "        unique_values = list(set(train_df[feature].unique()) | set(test_df[feature].unique()))\n",
    "        \n",
    "        # Create binary columns for each category\n",
    "        for value in unique_values:\n",
    "            column_name = f\"{feature}_{value}\"\n",
    "            train_df[column_name] = (train_df[feature] == value).astype(int)\n",
    "            test_df[column_name] = (test_df[feature] == value).astype(int)\n",
    "\n",
    "# 6. Text embeddings using TF-IDF\n",
    "# We'll use this to capture the semantic meaning of prompts\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=100,  # Limit number of features to avoid dimensionality issues\n",
    "    stop_words='english',\n",
    "    ngram_range=(1, 2)  # Include both unigrams and bigrams\n",
    ")\n",
    "\n",
    "# Fit on combined train and test prompts to ensure consistent vocabulary\n",
    "all_prompts = list(train_df['Prompt']) + list(test_df['Prompt'])\n",
    "vectorizer.fit(all_prompts)\n",
    "\n",
    "# Transform train and test sets\n",
    "train_tfidf = vectorizer.transform(train_df['Prompt'])\n",
    "test_tfidf = vectorizer.transform(test_df['Prompt'])\n",
    "\n",
    "# Convert to DataFrame and add as new columns\n",
    "tfidf_feature_names = vectorizer.get_feature_names_out()\n",
    "train_tfidf_df = pd.DataFrame(train_tfidf.toarray(), columns=[f'tfidf_{name}' for name in tfidf_feature_names])\n",
    "test_tfidf_df = pd.DataFrame(test_tfidf.toarray(), columns=[f'tfidf_{name}' for name in tfidf_feature_names])\n",
    "\n",
    "# Join with main dataframes\n",
    "train_df = pd.concat([train_df.reset_index(drop=True), train_tfidf_df], axis=1)\n",
    "test_df = pd.concat([test_df.reset_index(drop=True), test_tfidf_df], axis=1)\n",
    "\n",
    "# Show the size of our feature set\n",
    "print(f\"\\nTotal features in training data: {train_df.shape[1]}\")\n",
    "print(f\"Total features in test data: {test_df.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "55a72cb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1IAAAIjCAYAAAAJLyrXAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjEsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvc2/+5QAAAAlwSFlzAAAPYQAAD2EBqD+naQAAYQ1JREFUeJzt3Qd4lFXaxvE7jRI6QZpUEQUFUVCwokhVRBF2rSiWz7ZgASsqCjZUFFFE0V1EXcHCiopYVhQElaKgBNsiIEUBRUBqCinzXc8ZJyQhgbxhJlPy/13Xa6blnZPJIc4955znxPl8Pp8AAAAAACUWX/KHAgAAAAAMQQoAAAAAPCJIAQAAAIBHBCkAAAAA8IggBQAAAAAeEaQAAAAAwCOCFAAAAAB4RJACAAAAAI8IUgAAAADgEUEKAKLY6tWrFRcXpxdffDHkz2XPYc9lzxnQrFkznXXWWSoLn376qXt++1rWTjvtNHdEk8suu8z9fkpjxIgR7rUGABSPIAWg3HvmmWfcm8ZOnTqFuymuHYEjMTFRtWvXVocOHXTjjTfqhx9+COrPXBbhK9baFuzf8b6OcATGSAmA+V+HqlWr6pBDDtHf/vY3vfnmm8rNzS31uadMmaKxY8cGtb0Ayq84n8/nC3cjACCcTjrpJK1fv96NtCxfvlyHHnpo2Npibxy7d++uSy+9VPbnedu2bUpNTdXUqVO1a9cuPfLIIxo6dGje4+0xmZmZSkpKUkJCQomfp02bNqpTp46nN+s5OTnKyspSxYoV80YrbMTDzjVjxgyPP6n3ttkb6N27d6tChQqKjy/bzwHteY0994F65ZVXClx/+eWXNXPmTP373/8ucLv1g3r16pX6eex3Za+Z/b68ys7OdkelSpUUjiD12muv6V//+pe7np6erjVr1ujdd9/V0qVL3cjgO++8o+rVq3s+t42efvfddwVGVQGgtBJL/Z0AEANWrVqlefPmadq0abrmmms0efJk3XvvvWFt02GHHaYBAwYUuO3hhx9Wnz59dPPNN6tVq1Y688wz3e0WaEL9ZtcCXJUqVVxQ8xLWgs3CUzje2AcrQAUU/t0uWLDABanCtxeWlpam5OTkEj+PhevSstFQO8LFnrvw6/HAAw+4fwfDhg3TVVddpddffz1s7QMAw9Q+AOWaBadatWqpd+/ebuqQXS/K5s2bdckll7hPwWvWrKmBAwe6kaKi1if973//c+eyaXn2xv/YY4/V9OnTD6idKSkp7lN6e4P54IMP7nON1G+//abLL79cjRo1cqMRDRo00DnnnJP3KbyNIn3//feaM2dO3vSpwPqfwDoou+8f//iH6tat686T/76iPs3/6KOPdPTRR7uf94gjjnDBtCRrbgqfc19tK26NlI3W2fTHypUru5EsewO+bt26vUY5bIqY3d63b193+aCDDtItt9ziRtq8rpEKtOWNN95wvw97jexn79q1q1asWLHf85Xk+WxkbvHixercubMLUHfeeae7z0ZjrL82bNjQ/X5btGih+++/f6+fo/AaqUBfeeyxx/T888+777PvP+644/TVV1/t9/dl1wcPHqy3337btc2+98gjj9SHH364V/vt9bF+b6+JPc9zzz0XlHVXd9xxh3r06OF+5z/99FPe7SV5Tew1fe+999zoVqBvBV4fG3G85557XD+qUaOG++DglFNO0ezZsw+ovQBiGyNSAMo1C079+vVzIw4XXnihnn32Wfem0t5cBtj0KBsN+vLLL3Xddde5ESF742ZhqjALATZV8OCDD3Zv+uwNmb3Ztjfvtr7j3HPPLXVbmzRpolNPPdW9udu+fXuxU5v69+/v2nH99de7N4obN250Ix5r1651122NiN1nYeKuu+5y31N4CpmFKAsa9ubSRqT2xaZDnn/++br22mvdazJp0iT9/e9/d2+wbXqaFyVpW+EgZqHRfl+jRo3S77//rieffFJffPGFvvnmGxd6A+xNdc+ePd1aOAsTH3/8sR5//HH3ptt+r6VhIyQ2UmaBzKZhPvroo7r44ou1cOFCHSgL72eccYYuuOACFw4Dr4P9zPb62BRP+zpr1iz3e7I+MXr06BKtE9qxY4cbgbUwYW22fwM///zzfkexPv/8cxeSrX9Uq1ZNTz31lOtv1rcs7Bt73Xv16uUC/MiRI93rft9997n+FAz2gYYFd+vTNnpb0tfE+pP9jn799Vc98cQT7jZ7rLHH2VRC+xtgo132+kycONH1F/t3bx8SAMBebI0UAJRHixYtsjWivpkzZ7rrubm5vkaNGvluvPHGAo9788033ePGjh2bd1tOTo7v9NNPd7dPmjQp7/auXbv62rZt68vIyMi7zc574okn+lq2bLnfNtn5Bg0aVOz91jZ7TGpqqru+atWqAm34888/3fXRo0fv83mOPPJI36mnnrrX7XYe+/6TTz7Zl52dXeR99pwBTZs2dbfZaxSwbds2X4MGDXzHHHNM3m333nuve1xxz5f/nMW1bfbs2e6x9tXs3r3bV7duXV+bNm186enpeY+bMWOGe9w999yTd9vAgQPdbffdd1+Bc1obO3To4Nsfa0/+NgXa0rp1a19mZmbe7U8++aS7/dtvv/WVlP2+C7829lx224QJE/Z6fFpa2l63XXPNNb7k5OQC/c5+Zvv9BAT6SkpKim/Lli15t7/zzjvu9nfffXefvy+7XqFCBd+KFSvybrN+aLePGzcu77Y+ffq4tqxbty7vtuXLl/sSExOL7AOFWburVKlS7P3ffPONO8+QIUM8vya9e/cu8JoEWF/P/3sM/FuqV6+e74orrthvmwGUT0ztA1CuR6PsU/4uXbq46/bpvI2s2BS6/FOCbGTFPqm3T6oDbBRi0KBBBc63ZcsW90n4eeed5z7R3rRpkztsZME+2baRm8JTzrwKfIJu5y+KTW+z0TWbWvXnn3+W+nnsZy3peiibTpV/pM1GyqxYho1M2DTDUFm0aJEbbbPRkfxrp2yKl40a2jSuwmzULD+bvmUjMaVlo2H510/Z+cyBnDPApqjZ+Yv6HQcE+pk9r62hsmml+2N93KazlqbN3bp1cyN4AUcddZT7fQe+1/7d2EifjcBavwiwAi42uhYMRf0bONDXxPp64PdoI9D2b9mKbdj0xK+//joo7QYQewhSAMole8NngclClBWcsHUtdti0L5se9sknn+Q91tZU2DSlwgv9C1f3s++3D+6HDx/upjHlPwIFLOyN/4HYuXOn+2rTqop7822V/T744AMXEm19jU3d8hpomjdvXuLH2utQeO1LYMpVKKuj2e/FHH744XvdZ0EqcH+Aha3C08ssUBxI4LTploXPZw7knAE2PbSoIhc2bdOCq63lsRBjP1OgMINNXQtlmwt/b+D7A99r/duq7BVV+TJY1TCL+jdwoK+Jeemll1wwtH5i0xTtHBbGS/r9AMof1kgBKJds5GjDhg0uTNlR1GiVLWr3IrC/ja2XsRGoohzom0kr3Wyfnu8r6Nx0001uTZcVBfjvf//rgp2tH7Kf+ZhjjinR8+T/hD8YiisyUJJCD8ESioqDxZ0zGDuLFPU72Lp1q1snZ2HB1h3Z6JC98bdRk9tvv71EeywdSJtD+fN6+TeQ/99SMF4TK0lvxTlsJO3WW291RVbsZ7V/NytXrgz5zwQgOhGkAJRLFpTszdL48eP3us8W07/11luaMGGCezPbtGlTV+ChcPnpwtXZbNNQY9MAbQpUsNmCfqtmd8IJJxQ7IhVgbyatVLodNqXQFstbYYXAHkYHWj2tqJG4/OcMVFQLVEULjHrYm978BSAKjxp5aZv9XsyyZct0+umnF7jPbgvcH0tsyqZNFbU+aqONATaqGgns35SFmKIqFwajmqGx/bYC+615fU2K61v/+c9/3L9fO0f+x4R7KwQAkY2pfQDKHZt6ZG+YbHNOK1Ne+LASz7bOIlCy3EaXbHPTf/7zn3nnsE+5C4cwexNpJZat1LONdhX2xx9/lLrNtmbDKorZCE6gml1RLOxlZGTsFaoseNnGvQFWTdBCTTDYZsYWPAOsApptMmvhrX79+nltMHPnzs17nFUDtOlUhZW0bbZ+xV5zC7z5fzab1vjjjz+6tVKxJjAilH8EyEp3P/PMM4qU9tmHCDYaav0if4iy38uBsiqJVrHP1nm1bNky7zlL+ppY3ypqql5R57DKi/Pnzz/gNgOIXYxIASh3LCBZUDr77LOLvP/444936yNs1MresNl0n44dO7rRHXtDaOtv7BwWbkz+T7AtXJ188slq27atK9hgn3Lbmit7Q2Zll23vqf2x0RwbObI3dRZK7Hts3xxbGzJmzBhXWnpf32t7GVnBC9vPyfadspBjbbAy2gG2X46VerdNTm2KlAWSwqM6JWXroa688kpXNt7WZb3wwgvu+awMeoBNk7T1NfY4mzplb1ztcfY620hbfiVtm4382XowK8hgU7ssaAbKn9tI2JAhQxRrTjzxRDe6Z2Xmb7jhBtf3bISmLKfW7Y/tF2Vhx7YBsLLyFv6ffvppt/fUkiVLSnQOK/QQGD21DwZs5NL+zS1dutSta7R9sErzmljfso18rUy6lcy3whU2DdY+VLEPV2ydlQVwG82ygG7/hgJrsgCgMIIUgHLHApJNPypujyOryGdvpuxxNmXIFp7bovMbb7zRjaDY/faGy6b92JvF/BXj7I2XVZOz/XNsbxv7fgsCtjbJ9rUpCdsfxw57Hlv3Yeuh7E3i1Vdf7c6/L40bN3aBwopl2JtJC1IW/GwvK9vvJ8DaYm9OrRCFhUoLIqUNUjYyMG7cOBeQbEqdtdferOZfJ2ahxwKdVdizNVs2UmVruewNcOHKdF7aZutabLqljVTYehgbcbDfjQWs/FMIY4X1xRkzZrhQf/fdd7vXz4oqWHgubl1eWbOwYqNPtlbQftfWJ23tko0SlqSCnrERRtsvytjv1/4N2Xmtb9jv1/5tlOY1sf5nYc5Cvu0lZdM/LUhZP7KCLDaabOsK7d+ZBTn7AKPwBtAAEBBnNdDzrgEASsymL9mbOtuk1AIVgOLZyK5V17M1ewAQC1gjBQAlXFeVn01XslEYGzFq37592NoFRMO/FwtP77//vltDCACxgql9AFAC119/vXtzaBXzbNqRraeYN2+eHnrooaCXCgeina0NtOly9tWmadqaN9sT67bbbgt30wAgaJjaBwAlMGXKFFc+3IpN2OJ3K4JgC+mtwh+Agmzdm20ZYOuObJNo+wDCPnRg9BZALCFIAQAAAIBHrJECAAAAAI8IUgAAAADgEcUmJOXm5rod2KtVq1ZgY00AAAAA5YvP53P7GDZs2LDAvnWFEaQkF6Jsw0AAAAAAML/88osaNWqk4hCkJDcSFXixbE+YUMnKytJHH32kHj16KCkpKWTPA5QG/RORjP6JSEb/RKSib5bO9u3b3SBLICMUhyBlpQv/ms5nISrUQSo5Odk9B50ZkYb+iUhG/0Qko38iUtE3D8z+lvxQbAIAAAAAPCJIAQAAAIBHBCkAAAAA8IggBQAAAAAeEaQAAAAAwCOCFAAAAAB4RJACAAAAAI8IUgAAAADgEUEKAAAAADwiSAEAAACARwQpAAAAAPCIIAUAAAAAHhGkAAAAAMAjghQAAAAAeESQAgAAAIBoClKjRo3Scccdp2rVqqlu3brq27evli1bVuAxGRkZGjRokFJSUlS1alX1799fv//+e4HHrF27Vr1791ZycrI7z6233qrs7Owy/mkAAAAAlBdhDVJz5sxxIWnBggWaOXOmsrKy1KNHD+3atSvvMUOGDNG7776rqVOnusevX79e/fr1y7s/JyfHhajdu3dr3rx5eumll/Tiiy/qnnvuCdNPBQAAACDWJYbzyT/88MMC1y0A2YjS4sWL1blzZ23btk0TJ07UlClTdPrpp7vHTJo0Sa1bt3bh6/jjj9dHH32kH374QR9//LHq1auno48+Wvfff79uv/12jRgxQhUqVAjTTwcAAAAgVoU1SBVmwcnUrl3bfbVAZaNU3bp1y3tMq1at1KRJE82fP98FKfvatm1bF6ICevbsqeuuu07ff/+9jjnmmL2eJzMz0x0B27dvd1/tuewIlcC5Q/kcQGnRP7379ddftXnz5pCc26YzN2rUKCTnjkb0T0Qy+iciFX2zdEr6ekVMkMrNzdVNN92kk046SW3atHG3/fbbb25EqWbNmgUea6HJ7gs8Jn+ICtwfuK+4tVkjR47c63Yb3bJ1VqFm0xiBSEX/jAzr1q3T0qVLw92MiEP/RCSjfyJS0Te9SUtLi64gZWulvvvuO33++echf65hw4Zp6NChBUakGjdu7NZnVa9ePaTp1jpy9+7dlZSUFLLnAUqD/ulNamqqm4LcufM/VbPm4UE999atyzR37lWaO3eu2rVrF9RzRyv6JyIZ/RORir5ZOoHZalERpAYPHqwZM2a4Nw35p7LUr1/fFZHYunVrgVEpq9pn9wUe8+WXXxY4X6CqX+AxhVWsWNEdhVkHK4tOVlbPA5QG/bNk4uPjlZ6eripVWqtGjfZBPXdWlv/c9hz8LgqifyKS0T8Rqeib3pT0tQpr1T6fz+dC1FtvvaVZs2apefPmBe7v0KGD+0E++eSTvNusPLqVOz/hhBPcdfv67bffauPGjXmPseRtI0tHHHFEGf40AAAAAMqLxHBP57OKfO+8847bSyqwpqlGjRqqXLmy+3rllVe6aXhWgMLC0fXXX+/CkxWaMDYdzwLTJZdcokcffdSd4+6773bnLmrUCQAAAACiOkg9++yz7utpp51W4HYrcX7ZZZe5y0888YSb3mIb8VqlPavI98wzz+Q9NiEhwU0LtCp9FrCqVKmigQMH6r777ivjnwYAAABAeZEY7ql9+1OpUiWNHz/eHcVp2rSp3n///SC3DgAAAAAicI0UAAAAAEQjghQAAAAAeESQAgAAAACPCFIAAAAA4BFBCgAAAAA8IkgBAAAAgEcEKQAAAADwiCAFAAAAAB4RpAAAAADAI4IUAAAAAHhEkAIAAAAAjwhSAAAAAOARQQoAAAAAPCJIAQAAAIBHBCkAAAAA8IggBQAAAAAeEaQAAAAAwCOCFAAAAAB4RJACAAAAAI8IUgAAAADgEUEKAAAAADwiSAEAAACARwQpAAAAAPCIIAUAAAAAHhGkAAAAAMAjghQAAAAAeESQAgAAAACPCFIAAAAA4BFBCgAAAAA8IkgBAAAAgEcEKQAAAADwiCAFAAAAAB4RpAAAAADAI4IUAAAAAHhEkAIAAAAAjwhSAAAAAOARQQoAAAAAPCJIAQAAAIBHBCkAAAAA8IggBQAAAAAeEaQAAAAAwCOCFAAAAAB4RJACAAAAAI8IUgAAAAAQTUFq7ty56tOnjxo2bKi4uDi9/fbbBe6324o6Ro8enfeYZs2a7XX/ww8/HIafBgAAAEB5EdYgtWvXLrVr107jx48v8v4NGzYUOF544QUXlPr371/gcffdd1+Bx11//fVl9BMAAAAAKI8Sw/nkZ5xxhjuKU79+/QLX33nnHXXp0kWHHHJIgdurVau212MBAAAAICaDlBe///673nvvPb300kt73WdT+e6//341adJEF110kYYMGaLExOJ/tMzMTHcEbN++3X3NyspyR6gEzh3K5wBKi/7pTW5uripXrqykpFwlJgb3NbNz2rntOfh9+NE/Ecnon4hU9M3SKenrFefz+XyKADZl76233lLfvn2LvP/RRx91gWn9+vWqVKlS3u1jxoxR+/btVbt2bc2bN0/Dhg3T5Zdf7m4vzogRIzRy5Mi9bp8yZYqSk5OD9BMBAAAAiDZpaWlucGbbtm2qXr169AepVq1aqXv37ho3btw+z2PrqK655hrt3LlTFStWLPGIVOPGjbVp06Z9vljBSLczZ850P0dSUlLIngcoDfqnN6mpqercubPOPnuuUlLaBfXcmzenavr0zq4gj60jBf0TkY3+iUhF3ywdywZ16tTZb5CKiql9n332mZYtW6bXX399v4/t1KmTsrOztXr1ah1++OFFPsYCVlEhyzpYWXSysnoeoDTonyUTHx+v9PR0ZWXFKzs7uK+XndPObc/B76Ig+iciGf0TkYq+6U1JX6uo2Edq4sSJ6tChQ4k+mV2yZIl781G3bt0yaRsAAACA8iesI1I2/W7FihV511etWuWCkK13ssIRgaG1qVOn6vHHH9/r++fPn6+FCxe6Sn5Wuc+uW6GJAQMGqFatWmX6swAAAAAoP8IapBYtWuRCUMDQoUPd14EDB+rFF190l1977TXZMq4LL7xwr++36Xl2vxWPsDVPzZs3d0EqcB4AAAAAiLkgddppp7mQtC9XX321O4pi1foWLFgQotYBAAAAQBSvkQIAAACASEKQAgAAAACPCFIAAAAA4BFBCgAAAAA8IkgBAAAAgEcEKQAAAADwiCAFAAAAAB4RpAAAAADAI4IUAAAAAHhEkAIAAAAAjwhSAAAAAOARQQoAAAAAPCJIAQAAAIBHBCkAAAAA8IggBQAAAAAeEaQAAAAAwCOCFAAAAAB4RJACAAAAAI8IUgAAAADgEUEKAAAAADwiSAEAAACARwQpAAAAAPCIIAUAAAAAHhGkAAAAAMAjghQAAAAAeESQAgAAAACPCFIAAAAA4BFBCgAAAAA8IkgBAAAAgEcEKQAAAADwiCAFAAAAAB4RpAAAAADAI4IUAAAAAHhEkAIAAAAAjwhSAAAAAOARQQoAAAAAPCJIAQAAAIBHBCkAAAAA8IggBQAAAAAeEaQAAAAAwCOCFAAAAAB4RJACAAAAAI8IUgAAAADgEUEKAAAAAKIpSM2dO1d9+vRRw4YNFRcXp7fffrvA/Zdddpm7Pf/Rq1evAo/ZsmWLLr74YlWvXl01a9bUlVdeqZ07d5bxTwIAAACgPAlrkNq1a5fatWun8ePHF/sYC04bNmzIO1599dUC91uI+v777zVz5kzNmDHDhbOrr766DFoPAAAAoLxKDOeTn3HGGe7Yl4oVK6p+/fpF3vfjjz/qww8/1FdffaVjjz3W3TZu3DideeaZeuyxx9xIFwAAAADEVJAqiU8//VR169ZVrVq1dPrpp+uBBx5QSkqKu2/+/PluOl8gRJlu3bopPj5eCxcu1LnnnlvkOTMzM90RsH37dvc1KyvLHaESOHconwMoLfqnN7m5uapcubKSknKVmBjc18zOaee25+D34Uf/RCSjfyJS0TdLp6SvV0QHKZvW169fPzVv3lwrV67UnXfe6UawLEAlJCTot99+cyErv8TERNWuXdvdV5xRo0Zp5MiRe93+0UcfKTk5WaFm0xCBSEX/LDn/VON1fx3BdeGFr2rdunXuwB70T0Qy+iciFX3Tm7S0tOgPUhdccEHe5bZt2+qoo45SixYt3ChV165dS33eYcOGaejQoQVGpBo3bqwePXq4ohWhTLfWkbt3766kpKSQPQ9QGvRPb1JTU9W5c2edffZcpaS0C+q5N29O1fTpnd2aT1tHCvonIhv9E5GKvlk6gdlqUR2kCjvkkENUp04drVixwgUpWzu1cePGAo/Jzs52lfyKW1cVWHdlR2HWwcqik5XV8wClQf8sGZtCnJ6erqyseGVnB/f1snPaue05+F0URP9EJKN/IlLRN70p6WsVVftI/frrr9q8ebMaNGjgrp9wwgnaunWrFi9enPeYWbNmuXUFnTp1CmNLAQAAAMSysI5I2X5PNroUsGrVKi1ZssStcbLD1jH179/fjS7ZGqnbbrtNhx56qHr27Oke37p1a7eO6qqrrtKECRPc8OXgwYPdlEAq9gEAAAAIlbCOSC1atEjHHHOMO4ytW7LL99xzjysmsXTpUp199tk67LDD3Ea7HTp00GeffVZgWt7kyZPVqlUrN9XPyp6ffPLJev7558P4UwEAAACIdWEdkTrttNPk8/mKvf+///3vfs9hI1dTpkwJcssAAAAAIEbWSAEAAABAJCBIAQAAAIBHBCkAAAAA8IggBQAAAAAeEaQAAAAAwCOCFAAAAAB4RJACAAAAAI8IUgAAAADgEUEKAAAAADwiSAEAAACARwQpAAAAAPCIIAUAAAAAHhGkAAAAAMAjghQAAAAAeESQAgAAAACPCFIAAAAA4BFBCgAAAAA8IkgBAAAAgEcEKQAAAADwiCAFAAAAAB4RpAAAAADAI4IUAAAAAHhEkAIAAAAAjwhSAAAAAOARQQoAAAAAPCJIAQAAAIBHBCkAAAAA8IggBQAAAAAeEaQAAAAAwCOCFAAAAAB4RJACAAAAAI8IUgAAAADgEUEKAAAAADwiSAEAAACARwQpAAAAAPCIIAUAAAAAHhGkAAAAAMAjghQAAAAAeESQAgAAAACPCFIAAAAA4BFBCgAAAAA8IkgBAAAAgEcEKQAAAADwiCAFAAAAANEUpObOnas+ffqoYcOGiouL09tvv513X1ZWlm6//Xa1bdtWVapUcY+59NJLtX79+gLnaNasmfve/MfDDz8chp8GAAAAQHkR1iC1a9cutWvXTuPHj9/rvrS0NH399dcaPny4+zpt2jQtW7ZMZ5999l6Pve+++7Rhw4a84/rrry+jnwAAAABAeZQYzic/44wz3FGUGjVqaObMmQVue/rpp9WxY0etXbtWTZo0ybu9WrVqql+/fsjbCwAAAABhD1Jebdu2zU3dq1mzZoHbbSrf/fff78LVRRddpCFDhigxsfgfLTMz0x0B27dvz5tOaEeoBM4dyucASov+6U1ubq4qV66spKRcJSYG9zWzc9q57Tn4ffjRPxHJ6J+IVPTN0inp6xXn8/l8igAWkN566y317du3yPszMjJ00kknqVWrVpo8eXLe7WPGjFH79u1Vu3ZtzZs3T8OGDdPll1/ubi/OiBEjNHLkyL1unzJlipKTk4P0EwEAAACINrbEyAZnbBCnevXq0R2kLBX2799fv/76qz799NN9/kAvvPCCrrnmGu3cuVMVK1Ys8YhU48aNtWnTpn2e+0DZz2HTFbt3766kpKSQPQ9QGvRPb1JTU9W5c2edffZcpaS0C+q5N29O1fTpnV1BHltHCvonIhv9E5GKvlk6lg3q1Kmz3yCVGA0d4LzzztOaNWs0a9as/QadTp06KTs7W6tXr9bhhx9e5GMsYBUVsqyDlUUnK6vnAUqD/lky8fHxSk9PV1ZWvLKzg/t62Tnt3PYc/C4Kon8iktE/Eanom96U9LVKjIYQtXz5cs2ePVspKSn7/Z4lS5a4Nx9169YtkzYCAAAAKH/CGqRs+t2KFSvyrq9atcoFIVvv1KBBA/3tb39zpc9nzJihnJwc/fbbb+5xdn+FChU0f/58LVy4UF26dHGV++y6FZoYMGCAatWqFcafDAAAAEAsC2uQWrRokQtBAUOHDnVfBw4c6ApCTJ8+3V0/+uijC3yfjU6ddtppbnrea6+95h5ra56aN2/uglTgPAAAAAAQc0HKwtC+al3srw6GVetbsGBBCFoGAAAAAMWL38d9AAAAAIAiEKQAAAAAwCOCFAAAAAB4RJACAAAAgLIIUj///HNpvg0AAAAAym+QOvTQQ13Z8ldeeUUZGRnBbxUAAAAAxFqQsk1yjzrqKLdfU/369XXNNdfoyy+/DH7rAAAAACBWgpRtkPvkk09q/fr1euGFF7RhwwadfPLJatOmjcaMGaM//vgj+C0FAAAAgFgoNpGYmKh+/fpp6tSpeuSRR7RixQrdcsstaty4sS699FIXsAAAAAAg1hxQkFq0aJH+8Y9/qEGDBm4kykLUypUrNXPmTDdadc455wSvpQAAAAAQIRJL800WmiZNmqRly5bpzDPP1Msvv+y+xsf7c1nz5s314osvqlmzZsFuLwAAAABEZ5B69tlndcUVV+iyyy5zo1FFqVu3riZOnHig7QMAAACA2AhSy5cv3+9jKlSooIEDB5bm9AAAAAAQe2ukbFqfFZgozG576aWXgtEuAAAAAIitIDVq1CjVqVOnyOl8Dz30UDDaBQAAAACxFaTWrl3rCkoU1rRpU3cfAAAAAMSyUgUpG3launTpXrenpqYqJSUlGO0CAAAAgNgKUhdeeKFuuOEGzZ49Wzk5Oe6YNWuWbrzxRl1wwQXBbyUAAAAARHvVvvvvv1+rV69W165dlZjoP0Vubq4uvfRS1kgBAAAAiHmlClJW2vz11193gcqm81WuXFlt27Z1a6QAAAAAINaVKkgFHHbYYe4AAAAAgPKkVEHK1kS9+OKL+uSTT7Rx40Y3rS8/Wy8FAAAAALGqVEHKikpYkOrdu7fatGmjuLi44LcMAAAAAGIpSL322mt64403dOaZZwa/RQAAAAAQi+XPrdjEoYceGvzWAAAAAECsBqmbb75ZTz75pHw+X/BbBAAAAACxOLXv888/d5vxfvDBBzryyCOVlJRU4P5p06YFq30AAAAAEBtBqmbNmjr33HOD3xoAAAAAiNUgNWnSpOC3BAAAAABieY2Uyc7O1scff6znnntOO3bscLetX79eO3fuDGb7AAAAACA2RqTWrFmjXr16ae3atcrMzFT37t1VrVo1PfLII+76hAkTgt9SAAAAAIjmESnbkPfYY4/Vn3/+qcqVK+fdbuumPvnkk2C2DwAAAABiY0Tqs88+07x589x+Uvk1a9ZM69atC1bbAAAAACB2RqRyc3OVk5Oz1+2//vqrm+IHAAAAALGsVEGqR48eGjt2bN71uLg4V2Ti3nvv1ZlnnhnM9gEAAABAbEzte/zxx9WzZ08dccQRysjI0EUXXaTly5erTp06evXVV4PfSgAAAACI9iDVqFEjpaam6rXXXtPSpUvdaNSVV16piy++uEDxCQAAAACIRYml/sbERA0YMCC4rQEAAACAWA1SL7/88j7vv/TSS0vbHgAAAACIzSBl+0jll5WVpbS0NFcOPTk5mSAFAAAAIKaVqmqfbcSb/7A1UsuWLdPJJ59MsQkAAAAAMa9UQaooLVu21MMPP7zXaBUAAAAAxJqgBalAAYr169cH85QAAAAAEBtrpKZPn17gus/n04YNG/T000/rpJNOClbbAAAAACB2RqT69u1b4OjXr59GjBiho446Si+88EKJzzN37lz16dNHDRs2VFxcnN5+++29Ato999yjBg0auP2punXr5jb+zW/Lli1u/6rq1aurZs2abj8rW7MFAAAAABEVpHJzcwscOTk5+u233zRlyhQXekpq165dateuncaPH1/k/Y8++qieeuopTZgwQQsXLlSVKlXUs2dPZWRk5D3GQtT333+vmTNnasaMGS6cXX311aX5sQAAAAAgtBvyBsMZZ5zhjqLYaNTYsWN1991365xzzsnbv6pevXpu5OqCCy7Qjz/+qA8//FBfffWVjj32WPeYcePG6cwzz9Rjjz3mRroAAAAAICKC1NChQ0v82DFjxpTmKbRq1So3ymXT+QJq1KihTp06af78+S5I2VebzhcIUcYeHx8f70awzj333CLPnZmZ6Y6A7du35+2HZUeoBM4dyucASov+6Y2NxtuU46SkXCUmBvc1s3Paue05+H340T8RyeifiFT0zdIp6etVqiD1zTffuMOe5PDDD3e3/fTTT0pISFD79u3zHmfrnkrLQpSxEaj87HrgPvtat27dvSoH1q5dO+8xRRk1apRGjhy51+0fffSR21A41GwaIhCp6J8l5983b91fR3BdeOGrWrdunTuwB/0TkYz+iUhF3/QmLS0tdEHKCkRUq1ZNL730kmrVquVus415L7/8cp1yyim6+eabFcmGDRtWYFTNRqQaN26sHj16uKIVoWLB0zpy9+7dlZSUFLLnAUqD/ulNamqqOnfurLPPnquUlHZBPffmzamaPr2zW/Np60hB/0Rko38iUtE3SycwWy0kQerxxx93ozeBEGXs8gMPPODCSDCCVP369d3X33//vUABC7t+9NFH5z1m48aNBb4vOzvbVfILfH9RKlas6I7CrIOVRScrq+cBSoP+WTI2hTg9PV1ZWfHKzg7u62XntHPbc/C7KIj+iUhG/0Skom96U9LXKr60Ke2PP/7Y63a7bceOHQqG5s2buzD0ySefFHheW/t0wgknuOv2devWrVq8eHHeY2bNmuXWFdhaKgAAAAAIhVKNSFkRB5vGZyNTHTt2dLdZwLn11lvdnlIlZfs9rVixokCBiSVLlrg1Tk2aNNFNN93kRrlatmzpgtXw4cNdJT7bu8q0bt1avXr10lVXXeVKpNvw5eDBg10hCir2AQAAAIioIGWh5ZZbbtFFF12UV9XCijzYZrijR48u8XkWLVqkLl265F0PrFsaOHCgXnzxRd12221urynbF8pGnk4++WRX7rxSpUp53zN58mQXnrp27eqmwfTv39/tPQUAAAAAERWkrLLdM88840LTypUr3W0tWrRwG+Z6cdppp7n9oopjVf/uu+8+dxTHRq9sI2AAAAAAKCulWiMVsGHDBnfY1DsLUfsKRQAAAABQroPU5s2b3VS6ww47TGeeeaYLU8am9kV66XMAAAAACEuQGjJkiCsLuHbt2gIb2J5//vluDRMAAAAAxLJSrZGyPaT++9//qlGjRgVutyl+a9asCVbbAAAAACB2RqSskl7+kagA2wi3qI1uAQAAAEDlPUidcsopevnllwtU17NNcB999NEC5cwBAAAAIBaVamqfBSYrNmH7QO3evdvt9/T999+7Eakvvvgi+K0EAAAAgGgfkWrTpo1++uknt0HuOeec46b69evXT998843bTwoAAAAAYpnnEamsrCz16tVLEyZM0F133RWaVgEAAABALI1IWdnzpUuXhqY1AAAAABCrU/sGDBigiRMnBr81AAAAABCrxSays7P1wgsv6OOPP1aHDh1UpUqVAvePGTMmWO0DAAAAgOgOUj///LOaNWum7777Tu3bt3e3WdGJ/KwUOgAAAADEMk9BqmXLltqwYYNmz57trp9//vl66qmnVK9evVC1DwAAAACie42Uz+crcP2DDz5wpc8BAAAAoDwpVbGJ4oIVAAAAAJQHnoKUrX8qvAaKNVEAAAAAyptEryNQl112mSpWrOiuZ2Rk6Nprr92rat+0adOC20oAAAAAiNYgNXDgwL32kwIAAACA8sZTkJo0aVLoWgIAAAAA5aHYBAAAAACURwQpAAAAAPCIIAUAAAAAHhGkAAAAAMAjghQAAAAAeESQAgAAAACPCFIAAAAA4BFBCgAAAAA8IkgBAAAAgEcEKQAAAADwiCAFAAAAAB4RpAAAAADAI4IUAAAAAHhEkAIAAAAAjwhSAAAAAOARQQoAAAAAPCJIAQAAAIBHBCkAAAAA8IggBQAAAAAeEaQAAAAAwCOCFAAAAAB4RJACAAAAAI8IUgAAAADgEUEKAAAAAGItSDVr1kxxcXF7HYMGDXL3n3baaXvdd+2114a72QAAAABiWKIi3FdffaWcnJy869999526d++uv//973m3XXXVVbrvvvvyricnJ5d5OwEAAACUHxEfpA466KAC1x9++GG1aNFCp556aoHgVL9+/TC0DgAAAEB5FPFBKr/du3frlVde0dChQ90UvoDJkye72y1M9enTR8OHD9/nqFRmZqY7ArZv3+6+ZmVluSNUAucO5XMApUX/9CY3N1eVK1dWUlKuEhOD+5rZOe3c9hz8Pvzon4hk9E9EKvpm6ZT09Yrz+Xw+RYk33nhDF110kdauXauGDRu6255//nk1bdrUXV+6dKluv/12dezYUdOmTSv2PCNGjNDIkSP3un3KlClMCwQAAADKsbS0NJc5tm3bpurVq8dGkOrZs6cqVKigd999t9jHzJo1S127dtWKFSvcFMCSjkg1btxYmzZt2ueLFYx0O3PmTLfGKykpKWTPA5QG/dOb1NRUde7cWWefPVcpKe2Ceu7Nm1M1fXpnzZ07V+3aBffc0Yr+iUhG/0Skom+WjmWDOnXq7DdIRc3UvjVr1ujjjz/e50iT6dSpk/u6ryBVsWJFdxRmHawsOllZPQ9QGvTPkomPj1d6erqysuKVnR3c18vOaee25+B3URD9E5GM/olIRd/0pqSvVcSXPw+YNGmS6tatq969e+/zcUuWLHFfGzRoUEYtAwAAAFDeRMWIlC24tiA1cOBAJSbuafLKlSvduqYzzzxTKSkpbo3UkCFD3HSbo446KqxtBgAAABC7oiJI2ZQ+KzBxxRVXFLjd1kvZfWPHjtWuXbvcOqf+/fvr7rvvDltbAQAAAMS+qAhSPXr0UFE1MSw4zZkzJyxtAgAAAFB+Rc0aKQAAAACIFAQpAAAAAPCIIAUAAAAAHhGkAAAAAMAjghQAAAAAeESQAgAAAACPCFIAAAAA4BFBCgAAAAA8IkgBAAAAgEcEKQAAAADwiCAFAAAAAB4RpAAAAADAI4IUAAAAAHhEkAIAAAAAjwhSAAAAAOARQQoAAAAAPCJIAQAAAIBHBCkAAAAA8IggBQAAAAAeEaQAAAAAwCOCFAAAAAB4RJACAAAAAI8IUgAAAADgEUEKAAAAADxK9PoNAIDSSUuTMjKk3FwpJ0dKSJBq15bi+UgLAICoQ5ACgBDx+aTNm6XVq/3Hli17P6ZCBalhQ6lRI6lZMyk5ORwtBQAAXhGkACAENm6UvvhC+uOPPbfFxUkVK/pHomwUKjNT2r17T9BasEBq1046+GCGqAAAiHQEKQAIIpu69+WX0v/+579uoclGm5o3l5o0kSpV2vNYm+K3aZP066/+IGWXFy+Wvv/+CElXuPsBAEBkIkgBQJCsXSvNnu0faTKHHSZ17Fj8dD0blapb138cc4y0apW0cKG0Y0cFSRN1xx1/6p13pCpVyvTHAAAAJUCQAoAg+O47af58/7qolBTppJOk+vVL/v027e+QQ6SmTS1M/arvvqurTz6ppZNPlqZPlxo3DmXrAQCAV0zEB4ADYMHJ1kLNm+e/fPjh0rnnegtR+dlUwMMO2yjpdNWqlaUlS6TjjvOvnwIAAJGDIAUApZaoBQsO0fff+6/ZNL7OnYNVzvwL/fvfy3TUUdLvv0vdu0tffRWM8wIAgGAgSAFAKfgLQbygDRtqulGkbt2ko4/2T9ELlgYNdrvRrq5dpZ07pTPOkH74IXjnBwAApUeQAgCPbArf2LEHS7pEcXE+N1pk65tCoWpV6e23/aNdtidVjx7SmjWheS4AAFByBCkA8OiRR6TJk+u5yx06rHFlzUPJwtT770tHHCGtW+ef5mf7VAEAgPAhSAGAB6+8Ig0bFrg2RE2abCmT57VKgB995K/qt3y5dMEFUk5OmTw1AAAoAkEKAEpo6VLp6qv9lwcO/E3S2DJ9/oMPlj74wL+vlO1Xdc89Zfr0AAAgH4IUAJTAtm1S//5SerrUs6c0aND6sLSjdWvpX//yX37oIem998LSDAAAyj2CFACUoLjE5ZdLK1bIrYey6X1WqS9cbFrf4MH+y5dcIq1eHb62AABQXhGkAGA/Hn9ceustqUIF6T//kerUCXeLpMce81fy+/NP6e9/l7Kywt0iAADKF4IUAOzD4sV7ikuMHSsdd5wiQsWK0htvSLVqSYsWSQ8/HO4WAQBQvhCkAKAYGRnSpZdK2dn+UZ9rr1VEsQp+Tz/tv3z//VJqarhbBABA+UGQAoBi3H239MMPUv360rPPSnFxijgXXij17euf2nfZZUzxAwCgrBCkAKAIc+dKY8b4L1uVPNvHKRJZuLOQV7u2tGSJv5IfAAAo50FqxIgRiouLK3C0atUq7/6MjAwNGjRIKSkpqlq1qvr376/ff/89rG0GEP127PCP7li1viuvlHr3VkSzEbPx4/2XH3jAH6gAAEA5DlLmyCOP1IYNG/KOzz//PO++IUOG6N1339XUqVM1Z84crV+/Xv369QtrewFEvzvukFat8q9BCoxKRbrzz/fvc2Xrua65RsrNDXeLAACIbREfpBITE1W/fv28o85fdYe3bdumiRMnasyYMTr99NPVoUMHTZo0SfPmzdOCBQvC3WwAUWr+fP9UOfPCC1L16ooKNsVv3DipWjXpyy/3bNoLAABCI1ERbvny5WrYsKEqVaqkE044QaNGjVKTJk20ePFiZWVlqVu3bnmPtWl/dt/8+fN1/PHHF3vOzMxMdwRs377dfbXz2REqgXOH8jmA0qJ/+gs1XHVVony+OF1ySa5OOSWn2OINubm5qly5spKScpWYGNzXzM5p57bn8PL7sM+ZRoyI1803J+iOO3w666xsHXSQYgL9E5GM/olIRd8snZK+XnE+n60CiEwffPCBdu7cqcMPP9xN6xs5cqTWrVun7777zk3pu/zyywsEItOxY0d16dJFjzzyyD7XXtm5CpsyZYqSk5ND8rMAiHxvvtlS//73EapWLVPjx89S9eq7FW1ycuJ0882navXqGuradY2uv54FUwAAeJGWlqaLLrrIzYCrvo+pKREdpArbunWrmjZt6qbz2ae1pQ1SRY1INW7cWJs2bdrnixWMdDtz5kx1795dSUlJIXseoDTKe/9cuVI65phEZWTEaeLEbF1yyb7/NKampqpz5846++y5SklpF9S2bN6cqunTO2vu3Llq1877uRcsiFPnzv4JB59+mq0TT4yaP/PFKu/9E5GN/olIRd8sHcsGtpxof0Eq4qf25VezZk0ddthhWrFihesQu3fvduHKbg+wqn22lmpfKlas6I7CrIOVRScrq+cBSqM89k/7OOnGG/0b8J5+unT55Yn73TMqPj5e6enpysqKV3Z2cF8vO6ed256jNL+LU06R/u///OukbrghUYsX23pTxYTy2D8RPeifiFT0TW9K+lpFfLGJ/Gya38qVK9WgQQNXXMJ+yE8++STv/mXLlmnt2rVuLRUAlNSbb0offWQfskgTJkTmxrtePfywf2+ppUuliRPD3RoAAGJPRAepW265xZU1X716tavGd+655yohIUEXXnihatSooSuvvFJDhw7V7NmzXfEJm+pnIWpfhSYAIL9du6ShQ/eUPW/ZUjHBNhAOLAW9+26rdBruFgEAEFsiOkj9+uuvLjRZsYnzzjvPbbxrpc0P+qsM1RNPPKGzzjrLbcRraxVsSt+0adPC3WwAUeShh6RffpGaNZNuv10xxfaTat1a2rTJv1EvAAAInoieNf/aa6/t834riT5+/Hh3AIBXy5dLjz3mv/zEE1LlyoopNsX78celM8+UnnzSH6wOPTTcrQIAIDZE9IgUAIS6wMTu3VLPntI55ygmnXGG1KuXf4+s224Ld2sAAIgdBCkA5dKMGbZXnX/U5qmnYqPARHFsVCohQXrrLWn27HC3BgCA2ECQAlDu2DZyQ4b4L1uhicMOU0w74gjp2mv9l2+5RcrNDXeLAACIfgQpAOWOjUDZBrwNGvgr2pUH994rVasmff21rT8Nd2sAAIh+BCkA5crvv0v33++/PGqUVLWqygUrdmrl3c2dd/pH5QAAQOkRpACUKzYCtWOHdOyx0iWXqFy56SapYUNpzRqJYqcAABwYghSAcuObb6SJE/2Xx46V4svZX8Dk5D2jcbav1J9/hrtFAABEr3L2NgJAeS53bgUm7OsFF0gnnaRyaeBA6cgj/SHKpjYCAIDSIUgBKBemTZPmzPFvuvvIIyq3rAz6o4/uKbph0/wAAIB3BCkAMS8jw1/229x6q9Skico126S3Sxd/wYnhw8PdGgAAohNBCkDMe+IJafVq6eCDpdtuC3drws82Hw6MSr3yin/tGAAA8IYgBSCmbdggPfig/7JN6atSJdwtigxWtfDCC/1rxm6/PdytAQAg+hCkAMQ02zNp1y7p+OOliy4Kd2siiwXMpCRp5kzpo4/C3RoAAKILQQpAzFq0SHrxxT3lzm1KG/Zo3lwaPNh/2aY85uSEu0UAAEQPghSAmGRT1m680X95wACpU6dwtygy3XWXVKOGlJoqTZ4c7tYAABA9CFIAYtKUKdK8ef41UQ8/HO7WRK6UFP/0R3P33VJ6erhbBABAdCBIAYg5O3b4y5wHRlysWh+Kd/31UuPG0i+/SOPGhbs1AABEB4IUgJjz0EP+an0tWkhDhoS7NZHPNil+4IE9r93mzeFuEQAAkY8gBSCmLF8ujRmzZ/+oSpXC3aLocPHFUrt20rZte8rFAwCA4hGkAMSUoUOl3bulXr2ks84Kd2uiR0LCnk16n35aWrUq3C0CACCyEaQAxIwPPpBmzJASEyl3Xho9ekjdu0tZWf61ZQAAoHgEKQAxwUahbrrJf9nKnh9+eLhbFJ0eecQfQF991b8PFwAAKBpBCkBMeOop6aefpHr1pHvuCXdrotcxx/j33TJW+dD24wIAAHsjSAGIelahb+RI/2XbM6p69XC3KLrdf79UsaL06af+6ZIAAGBvBCkAUW/YMGnnTqljR+nSS8PdmujXtKl0ww3+y7fdJuXkhLtFAABEHoIUgKi2YIH00kv+y7aZbDx/1YIWTmvVkr7/fs/rCwAA9uAtB4CoZSMlgwf7L19+uX9ECsFhIeruu/2Xhw+X0tLC3SIAACILQQpA1HrmGWnxYqlGDemhh8LdmtgzaJDUrJm0fr2/nDwAANiDIAUgKq1bt2evo1GjpPr1w92i2GMFJx58cE8Rjz/+CHeLAACIHAQpAFFpyBBpxw6pUyfpmmvC3ZrYdcEFUvv2/tfaqvkBAAA/ghSAqGMluadOlRISpOeeo8BEKNlrO3q0//Kzz0orVoS7RQAARAbefgCIKlb0wNbumBtvlNq1C3eLYt/pp0tnnCFlZ0t33hnu1gAAEBkIUgCiyr33SqtWSY0b79mEF6H3yCNSXJx/JHDhwnC3BgCA8CNIAYga9gZ+zJg9FfuqVg13i8qPtm2lyy7zX771VsnnC3eLAAAIL4IUgKiQmenfKyo3VxowQDrrrHC3qPy57z6pUiXps8+kt94Kd2sAAAgvghSAqGAV4378UapXjz2NwqVRI+mWW/ZUTWSTXgBAeUaQAhDxvvnGv49RYEpfSkq4W1R+DRsmNWkirV3r378LAIDyiiAFIOKn9NnanJwc6e9/l/r1C3eLyrfkZOmJJ/yXH32UcugAgPKLIAUgot11l7R0qVSnjvT00+FuDcy550o9eki7d/tL0FN4AgBQHhGkAESsTz6RHn/cf/mFF6S6dcPdIhgrgz5unJSUJL3/vvTuu+FuEQAAZY8gBSAibdkiDRzov3zttVKfPuFuEfI77DDp5pv9l2+4Qdq5M9wtAgCgbBGkAEQcmyp2zTXSunXS4YfvGZVCZLn7bqlpU2nNGumee8LdGgAAyhZBCkDEmThR+s9/pMREafJkf4EDRJ4qVaQJE/yXn3xS+uqrcLcIAICyQ5ACEFG+/loaPNh/+YEHpA4dwt0i7EuvXtJFF/k3Sv6//5OyssLdIgAAykZEB6lRo0bpuOOOU7Vq1VS3bl317dtXy5YtK/CY0047TXFxcQWOa21BBYCo8+ef0t/+5i95ftZZ0q23hrtFKAnbINn29rLqikzDBACUFxEdpObMmaNBgwZpwYIFmjlzprKystSjRw/t2rWrwOOuuuoqbdiwIe941DY3ARBVbETDikusWiU1by69/LIUH9F/oRBw0EHSmDH+yyNGSD/9FO4WAQAQeomKYB9++GGB6y+++KIbmVq8eLE6d+6cd3tycrLq168fhhYCCBb7/MPKaFes6F8fVatWuFsELy65RHrlFWnmTH8g/uwz/xo3AABiVVT9b27btm3ua+3atQvcPnnyZL3yyisuTPXp00fDhw934ao4mZmZ7gjYvn27+2ojXnaESuDcoXwOIBr754wZcbrzzgTboUhjx2arbVtfxK+1yc3NVeXKlZWUlKvExOA21s5p57bniKa/F88+K7Vvn6gFC+I0alSO7rgjN2jn5u8nIhn9E5GKvlk6JX294ny+6NiT3t5QnH322dq6das+//zzvNuff/55NW3aVA0bNtTSpUt1++23q2PHjpo2bVqx5xoxYoRGjhy51+1TpkzZZwADEHw//1xdd955ijIyEtWjx2pdd12q2/AV0Wn27MZ68sn2SkjI1ejRc3XIIf4PwAAAiBZpaWm66KKL3CBO9erVoz9IXXfddfrggw9ciGrUqFGxj5s1a5a6du2qFStWqEWLFiUekWrcuLE2bdq0zxcrGOnW1np1795dSUlJIXseIFr65/r10kknJWrdujh17Zqr6dNzFC3/NFJTU90U47PPnquUlHZBPffmzamaPr2z5s6dq3btgnvuULP/o5x/foLefjterVv7tHBhtipVOvDz8vcTkYz+iUhF3ywdywZ16tTZb5CKiql9gwcP1owZM9ybin2FKNOpUyf3dV9BqmLFiu4ozDpYWXSysnoeIJL7p9WM6dfPv+lu69a2LipeycnRU10iPj5e6enpysqKV3Z2cF8vO6ed254jGv9W/POf0vz50o8/xmnEiKSgVvLj7yciGf0TkYq+6U1JX6uIftdig2UWot566y030tTcSnntx5IlS9zXBg0alEELAZSGDQhbmXPbM6pOHVsjJdWsGe5WIVjsd2qbKhur5vfee+FuEQAAwRfRQcpKn1sRCVu7ZHtJ/fbbb+6wT2rNypUrdf/997sqfqtXr9b06dN16aWXuuk2Rx11VLibD6AI2dnSxRdbVU6ruClNny4dcki4W4Vg691buv56/+VLL5XWrg13iwAAKEdB6tlnn3VzE23TXRthChyvv/66u79ChQr6+OOP3d5SrVq10s0336z+/fvrXauhDCAi94r6v/+T3nzT/v1Kb78tnXBCuFuFUBk9WjruOGnLFls3Je3eHe4WAQAQPBG9Rmp/dTCsQIRt2gsg8tk/5xtukF56SUpIkOzzkO7dw90qhJItRbXfc/v20oIF0rBhCup6KQAAwimiR6QAxIacHOmqq6Tx4+VKm7/4otS3b7hbhbJgS1snTdqzXspGIwEAiAURPSIFIPrZdK4BA6SpU63Snb8IgV0PWLt2rdt6IBSsdGmTJk1Ccm6UnIXmoUP9QcrWS1m4slEqAACiGUEKQMikpUn9+/sLS1gl0dde85c8zx+iWrVqrfT0tJA8f+XKyfrf/34kTEWARx6RvvtO+ugj6eyzpa++suqq4W4VAAClR5ACEBK2P9Q550iLF/ur8731ltSjR8HH2EiUhaguXV5RrVqtg/r8f/75o2bPHuCegyAVfomJ/vVSVlzkf//z9w1b4lq5crhbBgBA6RCkAATdwoX+6Vy//SalpPhLnJ94YvGPtxBVpw5zvWKd7RVme4Z17OgfkbrsMunVV/1TPgEAiDb87wtAUL3yinTqqf4Q1aaN/w3zvkIUypcWLaRp0/xTPd94w7/X1H4KtAIAEJEIUgCCYtcu/x5Rl1wiZWb618HMm+cvLADkZ0H75Zf9FRyfeUa6++5wtwgAAO8IUgAOmK2DsipsVpHP3hzbG2NbE1WtWrhbhkh1wQW26br/8kMP+TfvBQAgmhCkABxQafMHHvAXEPjpJ6lRI2nWLOn++1n3gv275hp/NT9z223S00+Hu0UAAJQcb3UAlMrcudLRR0vDh0tZWf6y5qmp0mmnhbtliCYWoIYN81+29VIPPxzuFgEAUDIEKQCerF8vXXGFf53Ljz9Kdev6C0z85z9S7drhbh2i0YMP+gO5sVB1550UoAAARD6CFIAS2bZNuusu6dBDpUmT/LddfbV/T6CLL/avjQJKw/rOffdJjz7qvz5qlDR4sJSTE+6WAQBQPIIUgH3680//G9tDDvEXBUhP96+J+uIL6bnnbA+ocLcQseLWW6UJE/ZU87PKj9u3h7tVAAAUjSAFoEi//CLdfLPUpIl/qtWWLdIRR0hvv+0PUewNhVAVoHj9dalSJen99/2h/eefw90qAAD2lljEbQDKKZtK9cEHcW7q3rvv7pla1batf7TgwgulRP5qYD/Wrl2rTZs2HdCmvf/8Z7KGDj1EP/xQQe3bZ+uhh37WwQdbQZNU1a1bV00s4QMAEEa8JQLKOVvU/9130pQp8frXv7pr06Y9fxasoMTtt0u9erEGCiUPUa1atVZ6eloQztZA0tvatq2jBg1qqf794/Tee8cqLi5H//vfj4QpAEBYEaSAKPiEfn8yMzNVsWLFEj8+N1datqyy5s6tqZkza2rVqsqSEiQlq0aNbPXuvVl9+25WixYZqlOnjuLieMOKkrF+biGqS5dXVKtW6wM+X05OnFJT/9Dq1QfpzTcPU40aP2vbtuPc8xCkAADhRJACouoT+uLYcNH+6kXXl3SKpJ6Szvzr0/6ATMXHf6QhQxpo/PjumjJlq6ZM8d9TuXIyn/7DMwtRdeq0D8q5evSQ1qzJ1uef52rbtjqSUvXGG1vVrp2UYPkfAIAwIEgBUfYJfWFr176vRYuG69hjn1GTJp3ypuvt2lVRmzZV0aZN1bR5cxXt2lWpwPclJOSobt0dathwqzuSkxvolFPW6ddfZyory1+H5s8/f9Ts2QP49B9h16KFT/37f6o77zxBmzZV1yOPVNecOdLzz/vX8AEAUNYIUkAUfkKf35YtP0o6WJmZJ2jt2qNlMwh//91fprywlBSpQQN/Jb4GDRKUkFBTkh1WRCJL0jqlpLRTdnZS0NsJHKi6ddPVpcsyTZ06SVWqPKUFCxLUvr10003+ypKU4gcAlCWCVDlbT2PrXRhZiF5ZWdLWrf5j82b/sXFjf0kX69tvCz42Pl466CB/cKpfX6pXT/KwjAqISNavpWc0deq1+uc/2+qtt6THHpMmTpSGD5f+8Q/6OQCgbBCkytl6Gta7RD7/tDz/RqSB0GSHbYxrt+/Npuxlq0qVDDVoUFV16lhgtk/vKVWO2FWvXpamTbNy/dJtt/krTw4dKj31lHTHHdLAgf69qAAACBXeZpWj9TSsd4kctj/Tjh3+sFT4sNsD+zcVxd4c2hQmO2yqXlraB1q8uJ86dpyhli27luWPAYTdGWf4i1G8+KJ/RGr1aunaa6WRI/0bSl99tVStWrhbCQCIRQSpcraeBmXDRo7WrvUfn32WIuk+LVrU1E3Ns6Bk99vIU3FszyZ781ejhlSzpj802Vc7Cn/Kvnz5FkkZIf+ZgEhllfuuvNK/YfS//iWNHi39+qt0yy3+QHXppf4pf0ccEe6WAgBiCUEK8MjCkBVzWLfOSjLvCUyBw27bYtkmT1NJw919+dm0u+rViz6qVg2sBQFQUsnJ0g03+EekXnlFeuQR6aefpPHj/YdtMH355VK/foxSAQAOHEEK+GtdUlqa9Mcf0oYN/mP9+j2X8x/2mH2NJgXYaJLNoKxRY5s+/3yyjjzyHNWrd7ALSRaWKlf2jzwBCK4KFaQrrpAuu0yaNcsfoqZPlyuXboeNTp17rn8Eq1u3gsUpQr15NgV/ACB2EKQQc2HIps3t3FnwsEIN9t5oX0eGh9lxNppk1fCaNvWHpaIOC1Lm669XqkOHQTr88ONVp87BIfv5ARRko7oWlOz45RfppZekf//bP0o1ebL/sA81zjrLP0p1+OG/qGPH0G6eTcEfAIgdBKly6Mcfbd+h0MjMzFTF/dQetsCTmRmn9PR4pacnKC0tvsBl//UEd1v+y7m5leXzVXXBqHBYsuv7W3dUEtZ0C0iFj4YNC163qnjlaepdqPpMKPtiLLQdwdO4sXT33dJdd0lffumf+vfmm/5R5ilT/EdCQiPl5PxXzZpVU7NmFVWzZlpQ/51T8AcAYgtBqhxJS9tgZQw0YMCAUp4h4a/NW2vk+1r4sNur/3W5qqQqf32tWui6nSu0ayVsCp0dVar4izUEyoLb3kqBy4UPeyzT7YLZZ0r6PLtCcM7obTtCx/59d+rkP558Ulq4UK6Muk39++kn+8d/sqv8Z4dNETz4YP9hH6BYsRf+PgAAAghS5Uhm5lYbD9Kxxz6jJk065d2elWWjPhWUllZB6elJyshIUmZmojIzC37dvTv43SUhIVcJCTlKTMx1h11PTMx/3X85O/t3rV79igYO/JsOOaSukpNzValSjvtqR+XKOapc2X+5UqVcz58iW3GI+Pg6qlqVT4lL0meCZe3a97Vo0XBlZu4O+rmjue2RMnoc6yN19nfihBP8h1X6mzHjO/Xp86QOPvhR/fFHLe3eLa1a5T+MvVy2sXXgYK82ACjf+F9AOZCb69+faNOmhpJu0vr1ffT7743ypsfZmwUv7I2DfVIbOOzNRVKSrTFarvXr31Lz5v3VoEELd1vgsO8pfNm+xrvEs//Us3btIq1e/Zheemm0QoW1C8WrVu2wkJTjt6lOoRaNbS+b0TQbWjnAubAxNlLXsKH9MfyXOnW6TrVr13JrJ62MulXo3LjRwuee6pzGRqcKj3Lb6LeVYwcAxD6CVAzJzvaPrASObdv2bPLqXzvUxR1Wja4wC0M2rc2mwtm0OKsol/+wvYvsqz2uuNGe5cu/1Pr1t6tZsw5q2bJFVI0usHYBkaSsRtNCcf6yGKkrC/Z3zkac7Gjf3v+BlAUr2/rAjt9+21Pp047831e79p5gZZtmW7iyD50AALGFIBWFLBTZaJL9T33z5oLBqTj2CWnlylu0c+cnatLkODVt2qzAGqJo+Z98qEYXgEgU6tG0UJy/LEYZwx2s2rbd83fYQpUFKftbbF9thD9QCTQ//wdV9gHTo3r33doumLVu7b8dABCdCFJRwMpyBz71tOkl9jU9vejH2siRfRpqhy2MthLcdtj/rFes+MCNurRo8bFatmxW1j8GAMQMm9YX+DCqxV8D8BauduwouK2Cbb0QqCq6a5cV4blVI0bIHXaO5s2lNm2kI46QWraUDj3Uf1hxCwpbAEBkI0hFmPR0+z/niVqx4iClpvpDk03NK8z+B2thyaaNBIKTHWzyGnkL5aNp8T2A0rO/vbYvlR2HHLLndltbZYHKNvtdsuRtHXvs5Vqzppr7+/7zz/7DqgbmZ3/LLaAFglX+o1Ej1mFFEvu9brRPOSWlpqb+tfY3eNjEGYhcBKkI8tlnUpcuR0v6QkuXFrzP/sdsU0psUXNgYTPVoqJrcX80Lr4HcOBsbWn9+vY3e5OWLLlRzz13stq3b+9mGHz/vf+wz1tWrrSZA/7S6zbr4Lvv/EdhFqJsbzvbG6vwYbcHqgpaGEPoQ1SrVq3dmsZXX31VnTt3VnpxU0ZKiUJIQOTirXgEsfnyOTk2nLRBDRpU1sEH13ThyUKTTdlDdC7uj5XF90AkiYXR48Caqy5WByifrCxpzRp/qAocgZBlo1e2DuuXX/zHvlSrVrBcu30IZ1O+rfhF4AhctyngVmgocNi62bKY3WDTIe3nsVG7/IdNaS/uemkub9uWoYyMLPf/WFuflpsbl3c5/22Br3FxPrcuzl6D+Hj/ZRO4bLfbY3bvTlZ6+vtKSTlMDzwQp5SUde7/Jf7H2RYegcv+64HL/q0/Cm77UfC6/+u2bT/o008H6LPPPlNre5MQJdsgBDCahlhHkIogFpg+/PBb9ep1lE44YTFFFcKAxfdAZEtL+y3mR49te4jANL7CcnL8BS4CQcpKsQcu27Fhg/9+Cye2XssOC2Be2ahXIFTZB3mBLSvyb19hhz3OHz72HBaOCt9mhwXEwgHJjrJhn0aG4hNJqxZyqis2YkewxcW1k3SWBgxIk7SriGOHpO0ejowy3QaB0TTEOoJUhDnooKxwNwEAItbu3dvK9ehxYFqfHZ067T3NzLZwsCCzc2eCNm9O1JYtSXlft21L0PbtidqxIyHvCFy3x2dkxP81K8If2AJBrGx/Pp8qVsxVUpJPFSrkqkIFn7tc+LaivvofZ4/Pzftq923evE7PP/+UjjzyH6pa9WA3kuQ/VOir/3J+9lr6fP4b93z1X7avf/yxWCtW/Edt296rU0/N0tKlRykrK8G9fv7Rrj1H4eu2ZYmFS/saOALX7bH+57KhsBp/HQfOfsakJNvoPkc+31alp/+kGjWaqHr1akpKynb3VaiQ4y77vxa8bqNkJR2pZFsRlAcEKQBA1GH0uOi1OunpNnJxoG8Lkv86qvz11RZbJahChaqaNOnfSkmpl/fG3wKBTXULHP6pcHsfdruNZNksMhvhsq+BY+PGX9Sx49HKyPhTOTk+tz9XKDRu/A81aZKvCkgQLF++0AWphg2vUbduu5Sb20bZ2QdeCcSClL2+P/00TfPm3a5jj31FDRt22itw2VcbfSzua/7LxgLg7t2J7pDqucO2TtnX9in52e/Spn3m//3ZUdRtOTnWf47QH38kupFIliggFhGkAACIgfVdFqK6dHlFtWoFfy1NYHTB5/tYBx10YOcPvMEPjHZZ2zMytoSs7dEw0lh8YLHCFStUrdpOV7CktGz0zIJX/mC1atUnSk0dr1atHlDNmkfkTbUsvGbNrlsQCkzZtMt27N/hkr5Xr17+a1b8xKoL25q8QKXhoi4Xvs3W7wW5EGLYBUaPQ4F1aWWLIAUAQIxUB61YsUlI1tdGc9ujeaQxWAIjgnYEbNtm6w3fUoMGg9Sy5RElCmKFA1bh9W75g1d6eoZ27typ+PgUV8DDihmuW+c/vLY9UBylcOCyisZWVGVfh+31Zl9DWFMjTKPHRWNdWtkiSAEAUAaiuTpoNLcdwQ1iFkxKYtOmHzRtWgctXLhYLVu215YtcoftqZb/675us42sLcQFbrPqlaVlbQ+EKyuiYiNk+Q+behi4nJ29Xbm5aW7tXaVK/jV3tk5vz7HnemCNXv71eYG1e0WNpIVy9Jh1aWWPIAUAQBmK5vVd0dx2hIeFCZueZ0fz5t6+N7CZdXFBa/v2PUVR8h87d+65HNjWy6Y0Br53/6r/dRwo+3AgI99hZSqPkvSlliw5TMnJNVwBmf0dgQqZ+3tMBZsPqvravt2Kx0TOKFwsi5kgNX78eI0ePVq//fab2rVrp3Hjxqljx47hbhYAAAAOYDPrA1kfZlMS8wcrO6ygiQUs/xTEgsfPP6/Xc8+9pEaNzlViok1LtGqWgSMu77L/dtt7zH9b4Ku/pHxAhb+OvUNZICAGVxu3F2n+vekqVUpUYuIZql49ca+Rt+JG5LzeVjnf7fa1LPagixQxEaRef/11DR06VBMmTFCnTp00duxY9ezZU8uWLVNd2+0QAAAAZS5UG12XdjNhm+IXGCErrr3PPXenOnbsqTp1Wnk6t780/p4S9oHKlvmPNWs+VmrqE2rTZpTq1j2qyMcUPgLnC1wu/nE5f21hsGdOYUaGXa/gwmRZqZg37dE/1dE/PXLvaZGFL9eqVUn9+tXUiScqasREkBozZoyuuuoqXX755e66Bar33ntPL7zwgu64445wNw8AAKBcCX2BktBuJlyajbn9e5L5Ky4WZ8eO3yW9r4MOGlrkptsHYtOmVLcubcGCr9W69TFuhG379ix99NFcHXdcZ2VnJ+WNvBU1Glfc7YHbtm7N1JIly+TzVfxrW4RKf32tXCBSZGbGu6M0EhO36sQTaypaRH2Q2r17txYvXqxhw4bl3RYfH69u3bpp/vz5xX6KYUfAtr82UNiyZYuybBJtiNi509LStHnzZiXlL52Tz/bt21WpUiVt27b4r13Ig2fXrmXu3Lt2LdWmTQe+z0VZnp+2h/78iYm5rn9u2vSZsrPjo6rtZX3uUJ+fthffP3ftWh51bS+L89P28Jx/z7m/U1pavQJ/P8v7675ly0JVqlRRLVpcrYMOahnUc//xx9daufLVkJ57y5ZFSk7OUbCF8nXfts3/93Hp0kVKT/e/t83NzVXt2hu1c+dn7v2xraeygiElLRqS3/Lly3XDDTfoyCNvVLVqjQrcZ1Mbc3MT/5ryaF8T/rqekHfk5PhvC3y1DacDlzMy0rV58zLVrn28Nm9uqnDb8df+DD4bYtyHON/+HhHh1q9fr4MPPljz5s3TCSeckHf7bbfdpjlz5mjhwoV7fc+IESM0cuTIMm4pAAAAgGjxyy+/qFGjgqExpkakSsNGr2xNVYCldRuNSklJUVwIV8jZaFPjxo3dL6W6bX4ARBD6JyIZ/RORjP6JSEXfLB0bZ7JRqYYNG+7zcVEfpGwH54SEBP3+u8053cOu1y+mzIstTiy8QLFmzbKbj2kdmc6MSEX/RCSjfyKS0T8Rqeib3tUoriJJPsGbyBsmVjO/Q4cO+uSTTwqMMNn1/FP9AAAAACBYon5Eytg0vYEDB+rYY491e0dZ+fNdu3blVfEDAAAAgGCKiSB1/vnn648//tA999zjNuQ9+uij9eGHH6pevXqKJDad8N577y3VvgdAqNE/Ecnon4hk9E9EKvpmaEV91T4AAAAAKGtRv0YKAAAAAMoaQQoAAAAAPCJIAQAAAIBHBCkAAAAA8IggVYbGjx+vZs2aqVKlSurUqZO+/PLLcDcJ5cyoUaN03HHHqVq1aqpbt6769u2rZcuWFXhMRkaGBg0apJSUFFWtWlX9+/ffa8NroCw8/PDDiouL00033ZR3G/0T4bRu3ToNGDDA9b/KlSurbdu2WrRoUd79Vr/LKgg3aNDA3d+tWzctX748rG1G+ZCTk6Phw4erefPmru+1aNFC999/v+uTAfTP4CNIlZHXX3/d7XdlJSi//vprtWvXTj179tTGjRvD3TSUI3PmzHFvQhcsWKCZM2cqKytLPXr0cPuuBQwZMkTvvvuupk6d6h6/fv169evXL6ztRvnz1Vdf6bnnntNRRx1V4Hb6J8Llzz//1EknnaSkpCR98MEH+uGHH/T444+rVq1aeY959NFH9dRTT2nChAlauHChqlSp4v5fbx8AAKH0yCOP6Nlnn9XTTz+tH3/80V23/jhu3Li8x9A/Q8DKnyP0Onbs6Bs0aFDe9ZycHF/Dhg19o0aNCmu7UL5t3LjRPqryzZkzx13funWrLykpyTd16tS8x/z444/uMfPnzw9jS1Ge7Nixw9eyZUvfzJkzfaeeeqrvxhtvdLfTPxFOt99+u+/kk08u9v7c3Fxf/fr1faNHj867zfpsxYoVfa+++moZtRLlVe/evX1XXHFFgdv69evnu/jii91l+mdoMCJVBnbv3q3Fixe7IdSA+Ph4d33+/PlhbRvKt23btrmvtWvXdl+tn9ooVf6+2qpVKzVp0oS+ijJjo6a9e/cu0A8N/RPhNH36dB177LH6+9//7qZGH3PMMfrnP/+Zd/+qVav022+/FeifNWrUcFP56Z8ItRNPPFGffPKJfvrpJ3c9NTVVn3/+uc444wx3nf4ZGokhOi/y2bRpk5u7Wq9evQK32/X//e9/YWsXyrfc3Fy39sSmqrRp08bdZn9kK1SooJo1a+7VV+0+INRee+01N/3ZpvYVRv9EOP38889u6pRN07/zzjtdH73hhhtcnxw4cGBeHyzq//X0T4TaHXfcoe3bt7sPlxISEtz7zgcffFAXX3yxu5/+GRoEKaAcf+r/3XffuU+sgEjwyy+/6MYbb3Tr96woDxBpHz7ZiNRDDz3krtuIlP0NtfUmFqSAcHrjjTc0efJkTZkyRUceeaSWLFniPixt2LAh/TOEmNpXBurUqeM+HShcWcqu169fP2ztQvk1ePBgzZgxQ7Nnz1ajRo3ybrf+aFNRt27dWuDx9FWUBZu6ZwV42rdvr8TERHdYQQlbHG2X7ZNT+ifCxSqdHXHEEQVua926tdauXesuB/og/69HONx6661uVOqCCy5w1SQvueQSV5zHqvUa+mdoEKTKgA37d+jQwc1dzf/Jll0/4YQTwto2lC9W+tRC1FtvvaVZs2a5Mqn5WT+1ilT5+6qVR7c3CvRVhFrXrl317bffuk9SA4eNANjUlMBl+ifCxaZBF94uwtajNG3a1F22v6f2hjR//7SpVlYdjf6JUEtLS3Pr7/OzD/Ht/aahf4YGU/vKiM2ptqFVeyPQsWNHjR071pWcvvzyy8PdNJSz6Xw27P/OO++4vaQC86JtwantKWFfr7zyStdfrQBF9erVdf3117s/sscff3y4m48YZ30ysF4vwMrz2p49gdvpnwgX+3TfFvTb1L7zzjvP7QX5/PPPu8ME9jx74IEH1LJlS/fG1fb1salVtmcfEEp9+vRxa6Ks+I5N7fvmm280ZswYXXHFFe5++meIhKgaIIowbtw4X5MmTXwVKlRw5dAXLFgQ7iahnLF/8kUdkyZNyntMenq67x//+IevVq1avuTkZN+5557r27BhQ1jbjfIrf/lzQ/9EOL377ru+Nm3auJLRrVq18j3//PMF7rcS08OHD/fVq1fPPaZr166+ZcuWha29KD+2b9/u/lba+8xKlSr5DjnkEN9dd93ly8zMzHsM/TP44uw/oQppAAAAABCLWCMFAAAAAB4RpAAAAADAI4IUAAAAAHhEkAIAAAAAjwhSAAAAAOARQQoAAAAAPCJIAQAAAIBHBCkAAAAA8IggBQAAAAAeEaQAADFv/vz5SkhIUO/evcPdFABAjIjz+Xy+cDcCAIBQ+r//+z9VrVpVEydO1LJly9SwYcNwNwkAEOUYkQIAxLSdO3fq9ddf13XXXedGpF588cUC90+fPl0tW7ZUpUqV1KVLF7300kuKi4vT1q1b8x7z+eef65RTTlHlypXVuHFj3XDDDdq1a1cYfhoAQKQgSAEAYtobb7yhVq1a6fDDD9eAAQP0wgsvKDAZY9WqVfrb3/6mvn37KjU1Vddcc43uuuuuAt+/cuVK9erVS/3799fSpUtdKLNgNXjw4DD9RACASMDUPgBATDvppJN03nnn6cYbb1R2drYaNGigqVOn6rTTTtMdd9yh9957T99++23e4++++249+OCD+vPPP1WzZk03LdDWVz333HN5j7Egdeqpp7pRKRvJAgCUP4xIAQBilq2H+vLLL3XhhRe664mJiTr//PPdWqnA/ccdd1yB7+nYsWOB6zZSZdMBbY1V4OjZs6dyc3PdiBYAoHxKDHcDAAAIFQtMNgqVv7iETcSoWLGinn766RKvsbIpf7YuqrAmTZoEtb0AgOhBkAIAxCQLUC+//LIef/xx9ejRo8B9tibq1Vdfdeum3n///QL3ffXVVwWut2/fXj/88IMOPfTQMmk3ACA6sEYKABCT3n77bTeNb+PGjapRo0aB+26//XbNmjXLFaKwMDVkyBBdeeWVWrJkiW6++Wb9+uuvrmqffZ8VmDj++ON1xRVXuPVSVapUccFq5syZJR7VAgDEHtZIAQBidlpft27d9gpRxirwLVq0SDt27NB//vMfTZs2TUcddZSeffbZvKp9Nv3P2O1z5szRTz/95EqgH3PMMbrnnnvYiwoAyjlGpAAAyMcq9k2YMEG//PJLuJsCAIhgrJECAJRrzzzzjKvcl5KSoi+++EKjR49mjygAwH4RpAAA5dry5cv1wAMPaMuWLa4Kn62RGjZsWLibBQCIcEztAwAAAACPKDYBAAAAAB4RpAAAAADAI4IUAAAAAHhEkAIAAAAAjwhSAAAAAOARQQoAAAAAPCJIAQAAAIBHBCkAAAAAkDf/D4syIgFdTRzVAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We can viz some patterns eg patient age, age distribution\n",
    "# But first let's fill missing values in the patient age column\n",
    "train_df['Patient_Age'].fillna(train_df['Patient_Age'].mean(), inplace=True)\n",
    "\n",
    "test_df['Patient_Age'].fillna(test_df['Patient_Age'].mean(), inplace=True)\n",
    "\n",
    "# Plotting age distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(train_df['Patient_Age'], bins=30, kde=True, color='blue', alpha=0.6)\n",
    "plt.title('Age Distribution in Training Data')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6668819",
   "metadata": {},
   "source": [
    "## Model Development\n",
    "\n",
    "We'll use NLP techniques to predict clinician responses. The ROUGE Score is mentioned as the evaluation metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "442d56e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features shape: (400, 162), Target shape: (400,)\n",
      "Data split successful.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = train_df.drop(columns=['Prompt', 'DDX SNOMED', 'Clinician', 'Years of Experience'])\n",
    "y = train_df['DDX SNOMED']\n",
    "print(f\"Features shape: {X.shape}, Target shape: {y.shape}\")\n",
    "\n",
    "# Let's split the data for training and validation\n",
    "try:\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    print(\"Data split successful.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error splitting data: {e}\")\n",
    "    print(\"Please adjust based on the actual data structure.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebdf53bf",
   "metadata": {},
   "source": [
    "## NLP Model Using Transformer-based Approaches\n",
    "\n",
    "Since this is a text-to-text generation task, we'll use a transformer-based model to predict clinician responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9b3843",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Loading google/flan-t5-base model and tokenizer...\n",
      "Successfully loaded google/flan-t5-base model\n",
      "Test output: Bonjour, c'est-à-dire?\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, DataCollatorForSeq2Seq\n",
    "from datasets import Dataset\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from rouge_score import rouge_scorer\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Initialize a pretrained model - using smaller model for memory efficiency\n",
    "try:\n",
    "    # Use a smaller model to reduce memory usage\n",
    "    model_name = \"google/flan-t5-small\"  # Changed from flan-t5-base to small to reduce memory usage\n",
    "    print(f\"Loading smaller model {model_name} to save memory...\")\n",
    "    \n",
    "    # Initialize tokenizer and model\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(model_name).to(device)\n",
    "    \n",
    "    print(f\"Successfully loaded {model_name} model\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading model: {e}\")\n",
    "    print(\"Consider trying a different model or approach.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178245fb",
   "metadata": {},
   "source": [
    "## Prepare Training Data\n",
    "\n",
    "We'll create a custom training dataset by combining the prompt with the engineered features to create a comprehensive input for our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3c5b6605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 340\n",
      "Validation samples: 60\n",
      "\n",
      "Example of enhanced input:\n",
      "--------------------------------------------------------------------------------\n",
      "i am a nurse with 8 years of experience in general nursing working in a health centres in kakamega county in kenya 14 years old girl came with malaise fever chills she completed al full dose one day ago investigation done bs for mps was negative salmonella type 3 not done pregnancy test negative the lmp started 2 days ago how can i manage the patient should i refer the patient for more investigation\n",
      "\n",
      "Additional context:\n",
      "Patient age: 30\n",
      "Patient gender: Female\n",
      "Facility level: Medium\n",
      "Key conditions...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Target output:\n",
      "--------------------------------------------------------------------------------\n",
      "treatment last menstrual period started 2 days ago investigations bs for mps negative pregnancy test negative salmonella type 3 not done management administer iv fluids for hydration antipyretics for fever investigate thoroughly to find cause blood slide for malarial parasites salmonella cultures blood culture if malaria antimalarials ensure compliance if typhoid antibiotics referral if symptoms persist\n"
     ]
    }
   ],
   "source": [
    "def prepare_input_for_model(row, include_features=True):\n",
    "    \"\"\"Prepare a comprehensive input for the model by combining the prompt with key features.\"\"\"\n",
    "    prompt = row['Prompt']\n",
    "    \n",
    "    # If we want to include engineered features\n",
    "    if include_features:\n",
    "        # Add key demographic information\n",
    "        features = []\n",
    "        \n",
    "        # Add patient age if available\n",
    "        if not pd.isna(row['Patient_Age']):\n",
    "            features.append(f\"Patient age: {int(row['Patient_Age'])}\")\n",
    "            \n",
    "        # Add patient gender\n",
    "        features.append(f\"Patient gender: {row['Patient_Gender']}\")\n",
    "        \n",
    "        # Add facility complexity\n",
    "        facility_levels = {0: 'Basic', 1: 'Medium', 2: 'High', 3: 'Very High'}\n",
    "        features.append(f\"Facility level: {facility_levels.get(row['Facility_Complexity'], 'Unknown')}\")\n",
    "        \n",
    "        # Add medical keywords if present\n",
    "        if len(row['Medical_Keywords']) > 0:\n",
    "            features.append(f\"Key conditions: {', '.join(row['Medical_Keywords'])}\")\n",
    "            \n",
    "        # Combine features with the original prompt\n",
    "        if features:\n",
    "            feature_text = \"\\n\".join(features)\n",
    "            enhanced_prompt = f\"{prompt}\\n\\nAdditional context:\\n{feature_text}\\n\\nProvide a detailed clinical reasoning and management plan:\"\n",
    "            return enhanced_prompt\n",
    "        \n",
    "    return f\"{prompt}\\n\\nProvide a detailed clinical reasoning and management plan:\"\n",
    "\n",
    "# Create train and validation datasets\n",
    "train_inputs, val_inputs, train_targets, val_targets = train_test_split(\n",
    "    train_df,\n",
    "    train_df['Clinician'],\n",
    "    test_size=0.15,  # Using 15% as validation\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Prepare the enhanced inputs\n",
    "train_enhanced_inputs = [prepare_input_for_model(row) for _, row in train_inputs.iterrows()]\n",
    "val_enhanced_inputs = [prepare_input_for_model(row) for _, row in val_inputs.iterrows()]\n",
    "\n",
    "print(f\"Training samples: {len(train_enhanced_inputs)}\")\n",
    "print(f\"Validation samples: {len(val_enhanced_inputs)}\")\n",
    "\n",
    "# Print an example of the enhanced input\n",
    "print(\"\\nExample of enhanced input:\")\n",
    "print(\"-\" * 80)\n",
    "print(train_enhanced_inputs[0][:500] + \"...\" if len(train_enhanced_inputs[0]) > 500 else train_enhanced_inputs[0])\n",
    "print(\"-\" * 80)\n",
    "print(\"\\nTarget output:\")\n",
    "print(\"-\" * 80)\n",
    "print(train_targets.iloc[0][:500] + \"...\" if len(train_targets.iloc[0]) > 500 else train_targets.iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2458378c",
   "metadata": {},
   "source": [
    "## Create Datasets for Transformer Model\n",
    "\n",
    "Now we'll format our data for the Hugging Face transformer library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31977300",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 340/340 [00:02<00:00, 162.31 examples/s]\n",
      "Map: 100%|██████████| 60/60 [00:00<00:00, 198.93 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created train dataset with 340 samples\n",
      "Created validation dataset with 60 samples\n",
      "\n",
      "Sample features in the dataset:\n",
      "['input', 'target', 'input_ids', 'attention_mask', 'labels']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def create_transformer_dataset(inputs, targets, tokenizer, max_length=256):  # Reduced from 512 to 256\n",
    "    \"\"\"Create a dataset compatible with the Hugging Face trainer.\"\"\"\n",
    "    # Create a dictionary with inputs and targets\n",
    "    dataset_dict = {\n",
    "        'input': inputs,\n",
    "        'target': targets\n",
    "    }\n",
    "    \n",
    "    # Convert to Dataset object\n",
    "    dataset = Dataset.from_dict(dataset_dict)\n",
    "    \n",
    "    # Define tokenization function\n",
    "    def tokenize_function(examples):\n",
    "        # Tokenize inputs with reduced max_length\n",
    "        model_inputs = tokenizer(\n",
    "            examples['input'],\n",
    "            max_length=max_length,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "        )\n",
    "        \n",
    "        # Tokenize targets with even shorter max_length to save memory\n",
    "        with tokenizer.as_target_tokenizer():\n",
    "            labels = tokenizer(\n",
    "                examples['target'],\n",
    "                max_length=128,  # Even shorter for targets\n",
    "                padding=\"max_length\",\n",
    "                truncation=True,\n",
    "            )\n",
    "        \n",
    "        # Replace padding token id with -100 for loss calculation\n",
    "        model_inputs[\"labels\"] = [\n",
    "            [(l if l != tokenizer.pad_token_id else -100) for l in label]\n",
    "            for label in labels[\"input_ids\"]\n",
    "        ]\n",
    "        \n",
    "        return model_inputs\n",
    "    \n",
    "    # Apply tokenization\n",
    "    tokenized_dataset = dataset.map(tokenize_function, batched=True)\n",
    "    return tokenized_dataset\n",
    "\n",
    "# Create datasets\n",
    "try:\n",
    "    # Set up tokenizer for padding\n",
    "    if tokenizer.pad_token is None:\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "    \n",
    "    # Add special handling for target tokenization\n",
    "    tokenizer.add_special_tokens({'additional_special_tokens': ['<target>']}) \n",
    "    \n",
    "    # Convert all targets to strings in case they aren't already\n",
    "    train_targets_list = [str(target) for target in train_targets.tolist()]\n",
    "    val_targets_list = [str(target) for target in val_targets.tolist()]\n",
    "    \n",
    "    # Sample a smaller subset of the training data to test the pipeline\n",
    "    sample_size = 100  # Start with just 100 examples to test\n",
    "    print(f\"Using a sample of {sample_size} examples for initial testing\")\n",
    "    \n",
    "    # Create tokenized datasets with the sample\n",
    "    train_dataset = create_transformer_dataset(\n",
    "        train_enhanced_inputs[:sample_size], \n",
    "        train_targets_list[:sample_size], \n",
    "        tokenizer\n",
    "    )\n",
    "    val_dataset = create_transformer_dataset(\n",
    "        val_enhanced_inputs[:min(30, len(val_enhanced_inputs))],  # Even smaller validation set \n",
    "        val_targets_list[:min(30, len(val_targets_list))], \n",
    "        tokenizer\n",
    "    )\n",
    "    \n",
    "    print(f\"Created train dataset with {len(train_dataset)} samples\")\n",
    "    print(f\"Created validation dataset with {len(val_dataset)} samples\")\n",
    "    \n",
    "    # Show dataset format\n",
    "    print(\"\\nSample features in the dataset:\")\n",
    "    print(list(train_dataset.features.keys()))\n",
    "except Exception as e:\n",
    "    print(f\"Error creating datasets: {e}\")\n",
    "    print(\"Attempting alternative approach...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4607c6c5",
   "metadata": {},
   "source": [
    "## Train the Model\n",
    "\n",
    "Now we'll set up and run the training process using the Hugging Face Trainer API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9c2524",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ready to start.\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments, EarlyStoppingCallback\n",
    "!pip install -q evaluate\n",
    "import evaluate\n",
    "import numpy as np\n",
    "\n",
    "# Load ROUGE metric\n",
    "rouge = evaluate.load('rouge')\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    \"\"\"Calculate ROUGE scores for evaluation.\"\"\"\n",
    "    predictions, labels = eval_pred\n",
    "    \n",
    "    # Decode predictions\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    \n",
    "    # Replace -100 with pad token id to properly decode labels\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    \n",
    "    # Compute ROUGE scores\n",
    "    result = rouge.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
    "    \n",
    "    # Filter out columns with '*' to keep the output clean\n",
    "    result = {k: round(v * 100, 2) for k, v in result.items() if '*' not in k}\n",
    "    return result\n",
    "\n",
    "# Set up data collator\n",
    "data_collator = DataCollatorForSeq2Seq(\n",
    "    tokenizer=tokenizer,\n",
    "    model=model,\n",
    "    padding=True\n",
    ")\n",
    "\n",
    "# Define training arguments with extreme memory optimizations for Colab free tier\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./kenya_clinical_model\",\n",
    "    # Extreme memory optimization settings\n",
    "    per_device_train_batch_size=1,      # Minimum batch size\n",
    "    per_device_eval_batch_size=1,       # Minimum batch size\n",
    "    gradient_accumulation_steps=16,     # Double gradient accumulation (was 8)\n",
    "    gradient_checkpointing=True,        # Trade compute for memory\n",
    "    fp16=torch.cuda.is_available(),     # Use mixed precision if available\n",
    "    optim=\"adafactor\",                  # Use memory-efficient optimizer instead of AdamW\n",
    "    # Reduce evaluation frequency drastically\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=200,                     # Evaluate much less frequently (was 100)\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=200,                     # Save less frequently (was 100)\n",
    "    # Other parameters\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"rouge1\",\n",
    "    greater_is_better=True,\n",
    "    learning_rate=5e-5,                 # Slightly higher learning rate for Adafactor\n",
    "    num_train_epochs=2,                 # Reduce epochs from 3 to 2\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=1,                 # Keep only the best model\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=100,                  # Log even less frequently\n",
    "    ddp_find_unused_parameters=False if torch.cuda.is_available() else None,\n",
    "    # Adding these to further reduce memory usage\n",
    "    max_grad_norm=0.3,                  # Lower max gradient norm\n",
    "    dataloader_num_workers=0,           # Don't use additional workers\n",
    ")\n",
    "\n",
    "# Initialize trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)],\n",
    ")\n",
    "\n",
    "print(\"Training configuration ready with memory optimizations.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184a7d3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='51' max='255' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 51/255 1:47:16 < 7:26:37, 0.01 it/s, Epoch 0.59/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='15' max='15' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15/15 02:14]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968a864e",
   "metadata": {},
   "source": [
    "## Evaluate the Model\n",
    "\n",
    "Let's evaluate our trained model on the validation set and visualize some predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39df2294",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, validation_inputs, validation_targets, num_examples=5):\n",
    "    \"\"\"Evaluate the model and show examples of predictions.\"\"\"\n",
    "    # Initialize ROUGE scorer\n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "    \n",
    "    # Generate predictions for each validation example\n",
    "    predictions = []\n",
    "    \n",
    "    for input_text in validation_inputs[:num_examples]:\n",
    "        # Tokenize the input\n",
    "        inputs = tokenizer(input_text, return_tensors=\"pt\", truncation=True, max_length=512).to(device)\n",
    "        \n",
    "        # Generate prediction\n",
    "        with torch.no_grad():\n",
    "            output_ids = model.generate(\n",
    "                inputs.input_ids,\n",
    "                max_length=256,\n",
    "                num_beams=4,\n",
    "                early_stopping=True\n",
    "            )\n",
    "        \n",
    "        # Decode the output\n",
    "        prediction = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "        predictions.append(prediction)\n",
    "    \n",
    "    # Calculate average ROUGE scores\n",
    "    scores = {'rouge1': 0, 'rouge2': 0, 'rougeL': 0}\n",
    "    \n",
    "    for i, (pred, ref) in enumerate(zip(predictions, validation_targets[:num_examples])):\n",
    "        # Display example\n",
    "        print(f\"\\nExample {i+1}:\\n{'-' * 40}\")\n",
    "        print(f\"Input:\\n{validation_inputs[i][:150]}...\")\n",
    "        print(f\"\\nReference:\\n{ref[:150]}...\")\n",
    "        print(f\"\\nPrediction:\\n{pred[:150]}...\")\n",
    "        \n",
    "        # Calculate scores\n",
    "        score = scorer.score(pred, ref)\n",
    "        \n",
    "        # Update running totals\n",
    "        scores['rouge1'] += score['rouge1'].fmeasure\n",
    "        scores['rouge2'] += score['rouge2'].fmeasure\n",
    "        scores['rougeL'] += score['rougeL'].fmeasure\n",
    "        \n",
    "        print(f\"\\nROUGE Scores:\")\n",
    "        print(f\"ROUGE-1: {score['rouge1'].fmeasure:.4f}\")\n",
    "        print(f\"ROUGE-2: {score['rouge2'].fmeasure:.4f}\")\n",
    "        print(f\"ROUGE-L: {score['rougeL'].fmeasure:.4f}\")\n",
    "    \n",
    "    # Calculate averages\n",
    "    for key in scores:\n",
    "        scores[key] /= num_examples\n",
    "    \n",
    "    print(f\"\\nAverage ROUGE Scores across {num_examples} examples:\")\n",
    "    print(f\"ROUGE-1: {scores['rouge1']:.4f}\")\n",
    "    print(f\"ROUGE-2: {scores['rouge2']:.4f}\")\n",
    "    print(f\"ROUGE-L: {scores['rougeL']:.4f}\")\n",
    "    \n",
    "    return scores\n",
    "\n",
    "# Uncomment to evaluate the model after training\n",
    "# print(\"Evaluating model on sample validation examples...\")\n",
    "# eval_scores = evaluate_model(model, val_enhanced_inputs, val_targets_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e4afef",
   "metadata": {},
   "source": [
    "## Generate Final Predictions for Test Set\n",
    "\n",
    "Now let's generate predictions for the test set using our trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202897e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_test_predictions(model, test_df):\n",
    "    \"\"\"Generate predictions for the test set.\"\"\"\n",
    "    print(\"Generating predictions for test set...\")\n",
    "    \n",
    "    predictions = []\n",
    "    ids = []\n",
    "    \n",
    "    for idx, row in test_df.iterrows():\n",
    "        # Prepare input with the same preprocessing as training data\n",
    "        input_text = prepare_input_for_model(row)\n",
    "        \n",
    "        # Tokenize the input\n",
    "        inputs = tokenizer(input_text, return_tensors=\"pt\", truncation=True, max_length=512).to(device)\n",
    "        \n",
    "        # Generate prediction\n",
    "        with torch.no_grad():\n",
    "            output_ids = model.generate(\n",
    "                inputs.input_ids,\n",
    "                max_length=256,\n",
    "                num_beams=4,\n",
    "                early_stopping=True\n",
    "            )\n",
    "        \n",
    "        # Decode the output\n",
    "        prediction = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "        \n",
    "        # Process according to challenge requirements (lowercase, remove punctuation, etc.)\n",
    "        prediction = preprocess_clinical_text(prediction)\n",
    "        \n",
    "        # Save prediction and ID\n",
    "        predictions.append(prediction)\n",
    "        ids.append(row['Master_Index'])\n",
    "        \n",
    "        # Progress update\n",
    "        if (idx + 1) % 10 == 0:\n",
    "            print(f\"Generated {idx + 1}/{len(test_df)} predictions\")\n",
    "    \n",
    "    # Create submission DataFrame\n",
    "    submission_df = pd.DataFrame({\n",
    "        'Master_Index': ids,\n",
    "        'Clinician': predictions\n",
    "    })\n",
    "    \n",
    "    return submission_df\n",
    "\n",
    "# Uncomment to generate predictions after training\n",
    "# submission_df = generate_test_predictions(model, test_df)\n",
    "# submission_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332231ee",
   "metadata": {},
   "source": [
    "## Save Submission File\n",
    "\n",
    "Finally, let's save our predictions to a submission file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8635b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_submission(submission_df, filename=\"kenya_clinical_submission.csv\"):\n",
    "    \"\"\"Save the submission DataFrame to a CSV file.\"\"\"\n",
    "    # Ensure columns match the sample submission format\n",
    "    sample_submission = pd.read_csv('SampleSubmission.csv')\n",
    "    required_columns = sample_submission.columns.tolist()\n",
    "    \n",
    "    # Check if columns match\n",
    "    if set(submission_df.columns) != set(required_columns):\n",
    "        print(f\"Warning: Submission columns {submission_df.columns.tolist()} don't match required columns {required_columns}\")\n",
    "    \n",
    "    # Save the file\n",
    "    submission_df.to_csv(filename, index=False)\n",
    "    print(f\"Submission saved to {filename}\")\n",
    "    \n",
    "    # Show first few rows\n",
    "    print(\"\\nFirst rows of submission file:\")\n",
    "    print(submission_df.head())\n",
    "\n",
    "# Uncomment to save submission after generating predictions\n",
    "# save_submission(submission_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0871bdea",
   "metadata": {},
   "source": [
    "## Alternative Approach: Simple Sequence-to-Sequence with LSTM\n",
    "\n",
    "If you want a simpler and potentially faster approach, you can also try an LSTM-based sequence-to-sequence model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b35924",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_simple_lstm_approach():\n",
    "    \"\"\"Train a simpler LSTM-based model as an alternative approach.\"\"\"\n",
    "    from tensorflow.keras.models import Model\n",
    "    from tensorflow.keras.layers import Input, LSTM, Dense, Embedding, Dropout\n",
    "    from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "    from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "    \n",
    "    # Prepare the data\n",
    "    train_inputs = [prepare_input_for_model(row, include_features=False) for _, row in train_inputs_df.iterrows()]\n",
    "    train_targets = train_targets_df.tolist()\n",
    "    \n",
    "    # Create tokenizers\n",
    "    input_tokenizer = Tokenizer(num_words=15000, oov_token=\"<OOV>\")\n",
    "    input_tokenizer.fit_on_texts(train_inputs)\n",
    "    target_tokenizer = Tokenizer(num_words=15000, oov_token=\"<OOV>\") \n",
    "    target_tokenizer.fit_on_texts(train_targets)\n",
    "    \n",
    "    # Convert to sequences\n",
    "    input_sequences = input_tokenizer.texts_to_sequences(train_inputs)\n",
    "    target_sequences = target_tokenizer.texts_to_sequences(train_targets)\n",
    "    \n",
    "    # Pad sequences\n",
    "    max_input_len = 300\n",
    "    max_target_len = 300\n",
    "    input_padded = pad_sequences(input_sequences, maxlen=max_input_len, padding='post')\n",
    "    target_padded = pad_sequences(target_sequences, maxlen=max_target_len, padding='post')\n",
    "    \n",
    "    # Define model\n",
    "    embedding_dim = 256\n",
    "    lstm_units = 256\n",
    "    \n",
    "    # Encoder\n",
    "    encoder_inputs = Input(shape=(max_input_len,))\n",
    "    encoder_embedding = Embedding(15000, embedding_dim)(encoder_inputs)\n",
    "    encoder_lstm = LSTM(lstm_units, return_state=True)\n",
    "    _, state_h, state_c = encoder_lstm(encoder_embedding)\n",
    "    encoder_states = [state_h, state_c]\n",
    "    \n",
    "    # Decoder\n",
    "    decoder_inputs = Input(shape=(max_target_len,))\n",
    "    decoder_embedding = Embedding(15000, embedding_dim)(decoder_inputs)\n",
    "    decoder_lstm = LSTM(lstm_units, return_sequences=True, return_state=True)\n",
    "    decoder_outputs, _, _ = decoder_lstm(decoder_embedding, initial_state=encoder_states)\n",
    "    decoder_dense = Dense(15000, activation='softmax')\n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "    \n",
    "    # Create and compile model\n",
    "    model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
    "    \n",
    "    # Prepare decoder input data (with start token)\n",
    "    decoder_input_data = np.zeros_like(target_padded)\n",
    "    decoder_input_data[:, 1:] = target_padded[:, :-1]\n",
    "    decoder_input_data[:, 0] = target_tokenizer.word_index['<OOV>']\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(\n",
    "        [input_padded, decoder_input_data],\n",
    "        target_padded,\n",
    "        batch_size=64,\n",
    "        epochs=10,\n",
    "        validation_split=0.2\n",
    "    )\n",
    "    \n",
    "    # Save the model and tokenizers\n",
    "    model.save('simple_lstm_model')\n",
    "    \n",
    "    return model, input_tokenizer, target_tokenizer\n",
    "\n",
    "# Uncomment to try the simple LSTM approach\n",
    "# try:\n",
    "#     print(\"Training simple LSTM model as an alternative...\")\n",
    "#     lstm_model, input_tokenizer, target_tokenizer = train_simple_lstm_approach()\n",
    "# except Exception as e:\n",
    "#     print(f\"Error training LSTM model: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e13713aa",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "We've now built a complete pipeline for training and evaluating models for the Kenya Clinical Reasoning Challenge:\n",
    "\n",
    "1. Created enhanced inputs with our engineered features\n",
    "2. Prepared datasets for transformer-based models\n",
    "3. Set up a training pipeline with appropriate evaluation metrics (ROUGE scores)\n",
    "4. Built code for evaluating the model and generating final predictions\n",
    "5. Added an alternative LSTM-based approach\n",
    "\n",
    "To improve performance further, consider:\n",
    "- Trying different pretrained models, especially ones fine-tuned for medical text\n",
    "- Experimenting with different prompt formats and feature combinations\n",
    "- Applying additional text cleaning to the targets\n",
    "- Using ensemble methods to combine predictions from multiple models\n",
    "- Expanding the training data with augmentation techniques\n",
    "\n",
    "The full pipeline is now ready to be executed. Uncomment the training lines to begin training, then evaluate and generate your submission."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
