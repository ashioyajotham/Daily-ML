{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this competition is to create algorithms and models that can solve tricky math problems written in LaTeX format. Your participation will help to advance AI models’ mathematical reasoning skills and drive frontier knowledge.\n",
    "\n",
    "Description\n",
    "Note: This is the second AIMO Progress Prize competition. It builds upon the first AIMO Progress Prize competition, which was won in July 2024 by Project Numina. This second competition has an increased prize pool, a new dataset of problems, increased compute for participants and updated rules for using open-source LLMs.\n",
    "\n",
    "The ability to reason mathematically is a critical milestone for AI. Mathematical reasoning is the foundation for solving many complex problems, from engineering marvels to intricate financial models. However, current AI capabilities are limited in this area.\n",
    "\n",
    "The AI Mathematical Olympiad (AIMO) Prize is a $10mn fund to spur the open development of AI models capable of performing as well as top human participants in the International Mathematical Olympiad (IMO).\n",
    "\n",
    "This second AIMO Progress Prize competition has 110 math problems in algebra, combinatorics, geometry and number theory. The difficulty has been increased from the first competition, and the problems are now around the National Olympiad level. The problems have also been designed to be 'AI hard' in terms of the mathematical reasoning required, which was tested against current open LLMs' capabilities.\n",
    "\n",
    "To address the challenge of train-test leakage, the competition uses novel math problems created by an international team of problem solvers. Using this transparent and fair evaluation framework, the competition will help to strengthen the benchmarks for assessing AI models' mathematical reasoning skills, without the risk of contamination from training data.\n",
    "This latest AIMO Progress Prize competition offers an exciting opportunity to drive innovation in the field of AI for Math, while also fostering healthy competition and supporting open science.\n",
    "\n",
    "Join us as we work towards a future where AI models’ mathematical reasoning skills are accurately and reliably assessed, driving progress and innovation.\n",
    "\n",
    "\n",
    "Submissions are evaluated on the accuracy between their predicted labels and the ground-truth labels. In other words, submissions are ranked by the fraction of predicted labels that exactly match the ground-truth labels.\n",
    "\n",
    "In this competition, every ground-truth label is an integer between 0 and 999, inclusive.\n",
    "\n",
    "You should arrive at this number by taking the problem solution modulo 1000. If, for instance, you believe the solution to a problem is 65521 should be reported as 521 and -900 should be reported as 100. To be clear, for positive integers larger than 1000, this means: report the last three digits, discarding any initial zero(s). Thus 1009 should be reported as 9.\n",
    "\n",
    "If a question asks for an answer a\n",
    " to be calculated modulo m\n",
    " where m\n",
    " is specified (not all questions are of this type), then calculate the residue a\n",
    " modulo m\n",
    " which is a′\n",
    " with 0≤a′<m\n",
    " and then report this answer modulo 1000\n",
    ". For example, if asked to calculate the positive integer 2025\n",
    " modulo 999\n",
    ", the final answer should be 27\n",
    ". However, if asked to calculate 2025\n",
    " modulo 1013\n",
    ", the final answer should be 12\n",
    ".\n",
    "\n",
    "Answers may require basic computations, e.g., ⌊1002–√⌋=141"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "import re\n",
    "\n",
    "def clean_latex(text):\n",
    "    \"\"\"Clean and format LaTeX output for better readability.\"\"\"\n",
    "    # Remove LaTeX delimiters while preserving the math\n",
    "    text = re.sub(r'\\\\\\(|\\\\\\)', '', text)\n",
    "    \n",
    "    # Format common math symbols\n",
    "    replacements = {\n",
    "        r'\\sqrt': '√',\n",
    "        r'\\cdot': '×',\n",
    "        r'\\times': '×',\n",
    "        r'\\div': '÷',\n",
    "        r'\\le': '≤',\n",
    "        r'\\ge': '≥',\n",
    "        r'\\neq': '≠',\n",
    "        r'\\pm': '±',\n",
    "    }\n",
    "    \n",
    "    for latex, symbol in replacements.items():\n",
    "        text = text.replace(latex, symbol)\n",
    "    \n",
    "    # Clean up spaces around operators\n",
    "    text = re.sub(r'\\s*([+\\-×÷=])\\s*', r' \\1 ', text)\n",
    "    \n",
    "    # Format exponents nicely\n",
    "    text = re.sub(r'\\^([0-9])', r'²', text)  # Simple case for squared\n",
    "    text = re.sub(r'\\^([0-9])', r'³', text)  # Simple case for cubed\n",
    "    \n",
    "    # Remove multiple spaces\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    \n",
    "    return text.strip()\n",
    "\n",
    "def generate_math_solution(prompt, max_length=512, temperature=0.7):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    huggingface_model = \"Qwen/Qwen2.5-Math-1.5B-Instruct\"\n",
    "    \n",
    "    tokenizer = AutoTokenizer.from_pretrained(huggingface_model)\n",
    "    model = AutoModelForCausalLM.from_pretrained(huggingface_model)\n",
    "    \n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", padding=True)\n",
    "    input_ids = inputs.input_ids.to(device)\n",
    "    attention_mask = inputs.attention_mask.to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output = model.generate(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            max_length=max_length,\n",
    "            num_return_sequences=1,\n",
    "            do_sample=True,\n",
    "            temperature=temperature,\n",
    "            pad_token_id=tokenizer.eos_token_id,\n",
    "            early_stopping=True,\n",
    "            no_repeat_ngram_size=3,\n",
    "            top_k=50,\n",
    "            top_p=0.95,\n",
    "        )\n",
    "    \n",
    "    output_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    \n",
    "    # Split the text into steps and format each step\n",
    "    steps = output_text.split('\\n')\n",
    "    formatted_steps = []\n",
    "    \n",
    "    for step in steps:\n",
    "        if step.strip():\n",
    "            # Clean LaTeX in the step\n",
    "            cleaned_step = clean_latex(step)\n",
    "            formatted_steps.append(cleaned_step)\n",
    "    \n",
    "    # Join the steps with proper spacing\n",
    "    return '\\n\\n'.join(formatted_steps)\n",
    "\n",
    "def format_and_print_solution(solution):\n",
    "    \"\"\"Print the solution in a nicely formatted way.\"\"\"\n",
    "    print(\"\\n=== Math Solution ===\\n\")\n",
    "    \n",
    "    # Split into lines and format each line\n",
    "    lines = solution.split('\\n')\n",
    "    for line in lines:\n",
    "        if line.strip():\n",
    "            if line.startswith(('Step', '1.', '2.', '3.', '4.', '5.')):\n",
    "                print(f\"\\n{line}\")\n",
    "            else:\n",
    "                print(line)\n",
    "    \n",
    "    print(\"\\n==================\\n\")\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    prompt = \"Solve the following equation: x² + 2x + 1 = 0\"\n",
    "    solution = generate_math_solution(prompt)\n",
    "    format_and_print_solution(solution)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
